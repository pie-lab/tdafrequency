---
title: "Analytic Code"
date: "Last updated `r Sys.Date()`"
output: 
  html_document:
    toc: TRUE
---

```{r, include = F}
knitr::opts_chunk$set(message = F, warning = F)
```


# Prepare the environment

```{r, warning=FALSE, message=FALSE, label = "libraries_data"}
library(here) # for engaging with working environment
library(rio) # for importing excel files
library(psych) # for scoring multiple choice items
library(R.utils) # just for the insert() function
library(tidyverse) # for data cleaning and manipulation
library(matrixStats)
library(kableExtra)

options(scipen=999)
```

# Derive the search engine frequency estimates

## Data loading and preparation

The csv files contain the raw data. These cannot be shared in raw form, but transformations of the raw data are publicly available on Dataverse (see the link below and on the home page). Here, we show how the raw data are loaded, for cleaning and description. Further down in the code, we show the data being saved into the format posted on Dataverse.

```{r, message = F, warning = F, eval = T, label = "load_raw_data_serps"}
serps_person <- read_csv(here("../../TDAfreqdata/SERPs/serps_rawdata_file_person.csv"))
serps_woman <- read_csv(here("../../TDAfreqdata/SERPs/serps_rawdata_file_woman.csv"))
serps_man <- read_csv(here("../../TDAfreqdata/SERPs/serps_rawdata_file_man.csv"))
serps_girl <- read_csv(here("../../TDAfreqdata/SERPs/serps_rawdata_file_girl.csv"))
serps_boy <- read_csv(here("../../TDAfreqdata/SERPs/serps_rawdata_file_boy.csv"))
```

Once loaded, the data are re-coded in the instances where empty results are automatically replaced with results for similarly spelled terms. See the manuscript for more description of this issue. Once cleaned, the counts from each raw data file are combined into a single data frame with all of the TDA + noun pairings.

```{r, warning=FALSE, message=FALSE, label = "data-prep_serps"}
NOUNS_LIST <- c("person", "woman", "man", "girl", "boy")

serps_person <- serps_person %>%
  mutate(
    count = if_else(condition = type == "Empty showing fixed spelling results",
                    true = 0,
                    false = count)
  )

serps_woman <- serps_woman %>%
  mutate(
    count = if_else(condition = type == "Empty showing fixed spelling results",
                    true = 0,
                    false = count)
  )

serps_man <- serps_man %>%
  mutate(
    count = if_else(condition = type == "Empty showing fixed spelling results",
                    true = 0,
                    false = count)
  )

serps_girl <- serps_girl %>%
  mutate(
    count = if_else(condition = type == "Empty showing fixed spelling results",
                    true = 0,
                    false = count)
  )

serps_boy <- serps_boy %>%
  mutate(
    count = if_else(condition = type == "Empty showing fixed spelling results",
                    true = 0,
                    false = count)
  )

### RE-ORGANIZE SERPS DATASETS - COMBINE PERSON-WORD FORMS
serps_all <- tibble(
  TDA = serps_person$term,
  person = serps_person$count,
  woman = serps_woman$count,
  man = serps_man$count,
  girl = serps_girl$count,
  boy = serps_boy$count
)

serps_all_onlyFreq <- serps_all %>%
  select(-TDA)
```

It's also necessary to fix special characters for many of the adjectives.

```{r, warning=FALSE, message=FALSE, label = "data-prep_serps_special_characters"}
# fix characters
serps_all$TDA <- sub("acharn√©", "achar", serps_all$TDA)
serps_all$TDA <- sub("b√™te", "bête", serps_all$TDA)
serps_all$TDA <- sub("blas\x8e", "blasé", serps_all$TDA)
serps_all$TDA <- sub("bont√©", "bonté", serps_all$TDA)
serps_all$TDA <- sub("bo√∂pis", "boöpis", serps_all$TDA)
serps_all$TDA <- sub("born√©", "borné", serps_all$TDA)
serps_all$TDA <- sub("d√©gag√©", "dégagé", serps_all$TDA)
serps_all$TDA <- sub("d√©pays√©", "dépaysé", serps_all$TDA)
serps_all$TDA <- sub("d√©sorient√©", "désorienté", serps_all$TDA)
serps_all$TDA <- sub("distingu√©", "distingué", serps_all$TDA)
serps_all$TDA <- sub("d√ºreresque", "düreresque", serps_all$TDA)
serps_all$TDA <- sub("√©clat", "éclat", serps_all$TDA)
serps_all$TDA <- sub("effar√©", "effaré", serps_all$TDA)
serps_all$TDA <- sub("√©l√©gante", "élégante", serps_all$TDA)
serps_all$TDA <- sub("√©lite", "élite", serps_all$TDA)
serps_all$TDA <- sub("ent√™t√©", "entêté", serps_all$TDA)
serps_all$TDA <- sub("espi√®gle", "espiègle", serps_all$TDA)
serps_all$TDA <- sub("fa√´rie", "faërie", serps_all$TDA)
serps_all$TDA <- sub("fain√©ant", "fainéant", serps_all$TDA)
serps_all$TDA <- sub("FALSE", "false", serps_all$TDA)
serps_all$TDA <- sub("outr√©", "outré", serps_all$TDA)
serps_all$TDA <- sub("pr√©cieuse", "précieuse", serps_all$TDA)
serps_all$TDA <- sub("r√©chauff√©", "réchauffé", serps_all$TDA)
serps_all$TDA <- sub("rou√©", "roué", serps_all$TDA)
serps_all$TDA <- sub("TRUE", "true", serps_all$TDA)
serps_all$TDA <- sub("unco√∂rdinated", "uncoördinated", serps_all$TDA)
serps_all$TDA <- sub("zo√∂id", "zoöid", serps_all$TDA)
serps_all$TDA <- sub("zo√∂philous", "zoöphilous", serps_all$TDA)
```


### 1. Calculate overall means and compare differences using t-tests

```{r, warning=FALSE, "analyses_serps_means"}
serps_all_means <- c()
for (j in 1:ncol(serps_person))
{
  serps_all_means[j] <- mean(unname(unlist(serps_all_onlyFreq[,j])), na.rm = TRUE)
}
names(serps_all_means) <- NOUNS_LIST
serps_all_means

serps_all_longForm <- serps_all %>%
  gather(form, value, person:boy)
serps_uncorrected_ttests <- pairwise.t.test(x = serps_all_longForm$value, 
                                             g = serps_all_longForm$form, 
                                             p.adjust.method = "none")
serps_holm_ttests <- pairwise.t.test(x = serps_all_longForm$value, 
                                             g = serps_all_longForm$form, 
                                             p.adjust.method = "holm")
serps_bonferroni_ttests <- pairwise.t.test(x = serps_all_longForm$value, 
                                             g = serps_all_longForm$form, 
                                             p.adjust.method = "bonferroni")
```

Next, show the p-values for the uncorrected t-tests of means, then the holm-corrected and bonferroni-corrected p-values. None of the t-tests are significant when using corrections of either type. If using uncorrected means (not recommended), the only significant difference in means is for girl-woman; the p-value for girl-person is just above the significance threshold at p>.05.

```{r, warning=FALSE, label = "analyses_serps_means_pvalues"}
round(serps_uncorrected_ttests$p.value, 3)
round(serps_holm_ttests$p.value, 3)
round(serps_bonferroni_ttests$p.value, 3)
```

```{r, eval = F, echo = F, label = "serps_ttest_tables_apa"}
apa_table(serps_uncorrected_ttests$p.value, caption = "P-values of uncorrected t-tests comparing mean adjective SERPs count by person-word.", placement = "h")
apa_table(serps_holm_ttests$p.value, caption = "P-values of Holm-corrected t-tests comparing mean adjective SERPs count by person-word.", placement = "h")
apa_table(serps_bonferroni_ttests$p.value, caption = "P-values of Bonferroni-corrected t-tests comparing mean adjective SERPs count by person-word.", placement = "h")
```


### 2. Calculate z-scores

Now that we have compared the raw means in the prior step, we create a table of the zscores of the 10-year averages for each TDA + noun ngram. These are the data posted on Dataverse, as shown below.

```{r, warning=FALSE, "analyses_serps_zscores"}
serps_all_zscores <- serps_all %>%
  mutate(
    TDA = serps_person$term,
    person_zscore = (person - mean(person, na.rm = TRUE))/sd(person, na.rm = TRUE),
    woman_zscore = (woman - mean(woman, na.rm = TRUE))/sd(woman, na.rm = TRUE),
    man_zscore = (man - mean(man, na.rm = TRUE))/sd(man, na.rm = TRUE),
    girl_zscore = (girl - mean(girl, na.rm = TRUE))/sd(girl, na.rm = TRUE),
    boy_zscore = (boy - mean(boy, na.rm = TRUE))/sd(boy, na.rm = TRUE)
  ) %>%
  select(TDA, person_zscore:boy_zscore)
```


```{r, eval = T, echo = T, label = "save_serps_zscores"}
write_csv(serps_all_zscores, 
          file = here("data/serps/serps_all_zscores.csv"))
```

This csv file (above) has been posted publicly on Dataverse (see doi). All subsequent analyses of the search engine results data are based on this file, including the database of search engine estimates (see [here](https://pie-lab.github.io/tdafrequency/serps-frequency.html)).

*ADD DOI LINK TO THE SENTENCE ABOVE*

The following code clears the environment and loads the data directly from Dataverse.

*CHANGE THIS TO PULL THE ZSCORES FILE FROM DATAVERSE.*
```{r, echo = T, label = "load_serps_zscores"}
rm(list=ls())
serps_all_zscores <- read_csv(here("data/serps/serps_all_zscores.csv"))
```

```{r, eval = F, echo = T, label = "load_serps_zscores_dataverse"}
library(dataverse)
library(data.table)

Sys.setenv("DATAVERSE_SERVER" = "dataverse.harvard.edu")
writeBin(get_file("TDA_data_scored.tab", "doi:10.7910/DVN/5T80PF"), "TDA_data_scored.tab")
TDA_data_scored.tab <- fread("TDA_data_scored.tab", na.strings=getOption("<NA>","NA"))
data <- as.data.frame(TDA_data_scored.tab)
rm(TDA_data_scored.tab)
```


### 3. Correlations between the 5 TDA + noun vectors

```{r, warning=FALSE, label = "analyses_serps_cors"}
serps_zscores <- subset(serps_all_zscores, select = -c(TDA))
cor_table_serps <- corr.test(serps_zscores, 
                                    use = "pairwise",
                                    method = "pearson",
                                    alpha = .05,
                                    ci = TRUE)

cor_serps_ci <- tibble(
  group1 = c("person", "person", "person", "person", "woman", 
             "woman", "woman", "man", "man", "girl"),
  group2 = c("woman", "man", "girl", "boy", "man", 
             "girl", "boy", "girl", "boy", "boy"),
  lower_bound = cor_table_serps$ci$lower,
  r = cor_table_serps$ci$r,
  upper_bound = cor_table_serps$ci$upper,
  p_value = cor_table_serps$ci$p
)
```

```{r , echo = F, label = "serps_cor_tables_apa"}
cor_serps_ci <- as.data.frame(cor_serps_ci)
cor_serps_ci$p_value <- round(cor_serps_ci$p_value, 3)
cor_serps_ci$lower_bound <- round(cor_serps_ci$lower_bound, 3)
cor_serps_ci$r <- round(cor_serps_ci$r, 3)
cor_serps_ci$upper_bound <- round(cor_serps_ci$upper_bound, 3)

#apa_table(cor_table_serps$r,
#          caption = "Correlations between SERPs person-words.",
#          placement= "h")
#apa_table(cor_serps_ci,
#          caption = "Correlations between SERPs person-words, with confidence intervals.",
#          placement= "h")
```

The table below shows the correlations between noun pairs with the lower and upper bounds of the 95% confidence intervals.

```{r, warning=FALSE, echo = F, label = "analyses_serps_cors_cis"}
cor_serps_ci
```


### 4. Calculate the search engine frequency index

Here, we find the frequencies index by finding the average of the z-scores across all 5 TDA + noun pairs for each TDA *after* removing the max z-score for each TDA. In other words, find the average among all but the largest z-score for each TDA. This approach is used to reduce the skew introduced in a few cases where the pairing of a specific TDA + noun is part of a song, book, famous individual, etc.

Output from the following section of code is used to populate the serps column of the [database of frequencies](https://pie-lab.github.io/tdafrequency/serps-frequency.html) provided on this website.

```{r, warning=FALSE, label = "analyses_serps_freq-index"}
bucket <- c()
for (j in 1:nrow(serps_zscores)) 
{
  vector_i <- c()
  vector_i <- unname(unlist(serps_zscores[j,]))
  vector_i <- vector_i[vector_i != max(vector_i, na.rm = TRUE)]
  freq_val <- mean(vector_i, na.rm = TRUE)
  bucket[j] <- freq_val
}

serps_freq_index <- serps_zscores %>%
  mutate(
    TDA = serps_all_zscores$TDA,
    freq_index = bucket
  )  %>%
    select(TDA, everything())
```

```{r , echo = F, label = "top_serps_table_apa"}
write_csv(serps_freq_index, 
          file = here("data/serps/serps_freq_index.csv"))

present_table2 <- serps_freq_index %>%
  arrange(desc(freq_index)) %>%
  select(TDA, freq_index)

#apa_table(present_table2[1:10,],
        #  caption = "Top 10 adjectives with the highest frequency index.",
        #  placement= "h")
```


# Derive the ngram frequency estimates

## Data loading and preparation

The csv files contain the raw data. As with the search engine results, these cannot be shared in raw form, but transformations of the raw data are publicly available on Dataverse (see the link below and on the home page). Here, we show how the raw data are loaded, for cleaning and description. Further down in the code, we show the data being saved into the format available on Dataverse.

```{r, message = F, warning = F, eval = T, label = "load_raw_data"}
ngrams_person <- read_csv("../../TDAfreqdata/ngrams/ngrams_rawdata_file_person.csv")
ngrams_woman <- read_csv("../../TDAfreqdata/ngrams/ngrams_rawdata_file_woman.csv")
ngrams_man <- read_csv("../../TDAfreqdata/ngrams/ngrams_rawdata_file_man.csv")
ngrams_girl <- read_csv("../../TDAfreqdata/ngrams/ngrams_rawdata_file_girl.csv")
ngrams_boy <- read_csv("../../TDAfreqdata/ngrams/ngrams_rawdata_file_boy.csv")
```

Once loaded, we derive the means for each term + noun ngram across the 10 year period from 2010 to 2019. These averages are then combined in a new data frame.

```{r, warning=FALSE, message=FALSE, label = "data-prep_ngrams"}
NOUNS_LIST <- c("person", "woman", "man", "girl", "boy")

### AVERAGE NGRAMS DATA ACROSS YEARS
select_vars <- c("freq.2010","freq.2011","freq.2012","freq.2013","freq.2014",
                            "freq.2015","freq.2016","freq.2017","freq.2018","freq.2019")

ngrams_person <- ngrams_person %>%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_woman <- ngrams_woman %>%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_man <- ngrams_man %>%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_girl <- ngrams_girl %>%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_boy <- ngrams_boy %>%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

### COMBINE INTO ONE TABLE

ngrams_all_avgfreq <- tibble(
  TDA = ngrams_person$term,
  freq_avg_person = ngrams_person$freq_avg_all_years,
  freq_avg_woman = ngrams_woman$freq_avg_all_years,
  freq_avg_man = ngrams_man$freq_avg_all_years,
  freq_avg_girl = ngrams_girl$freq_avg_all_years,
  freq_avg_boy = ngrams_boy$freq_avg_all_years
)
```

It's also necessary to fix special characters for many of the adjectives.

```{r, warning=FALSE, message=FALSE, label = "data-prep_ngrams_special_characters"}
# fix characters
ngrams_all_avgfreq$TDA <- sub("acharn√©", "acharné", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("b√™te", "bête", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("blas\x8e", "blasé", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("bont√©", "bonté", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("bo√∂pis", "boöpis", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("born√©", "borné", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("d√©gag√©", "dégagé", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("d√©pays√©", "dépaysé", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("d√©sorient√©", "désorienté", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("distingu√©", "distingué", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("d√ºreresque", "düreresque", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("√©clat", "éclat", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("effar√©", "effaré", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("√©l√©gante", "élégante", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("√©lite", "élite", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("ent√™t√©", "entêté", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("espi√®gle", "espiègle", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("fa√´rie", "faërie", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("fain√©ant", "fainéant", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("FALSE", "false", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("outr√©", "outré", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("pr√©cieuse", "précieuse", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("r√©chauff√©", "réchauffé", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("rou√©", "roué", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("TRUE", "true", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("unco√∂rdinated", "uncoördinated", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("zo√∂id", "zoöid", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("zo√∂philous", "zoöphilous", ngrams_all_avgfreq$TDA)
```


## Analyses

### 1. Calculate overall means and compare differences using t-tests

Calculate the overall means for each of the TDA + noun vectors. In other words, find the means for all the TDA + person ngrams, TDA + man ngrams, woman, girl, and boy. Then compare the means with t-tests. This is repeated using holm and bonferroni corrections.

```{r, warning=FALSE, label = "analyses_ngrams_means"}
# drop the column of TDA labels
ngrams_avgfreq <- subset(ngrams_all_avgfreq, select = -c(TDA))
means_vector <- c()
for (j in 1:ncol(ngrams_avgfreq))
{
  means_vector[j] <- mean( unname(unlist(ngrams_avgfreq[,j])), na.rm = TRUE)
}

names(means_vector) <- NOUNS_LIST
means_vector

ngrams_all_longForm <- ngrams_avgfreq %>%
  gather(form, value, freq_avg_person:freq_avg_boy)

ngrams_uncorrected_ttests <- pairwise.t.test(x = ngrams_all_longForm$value, 
                                             g = ngrams_all_longForm$form, 
                                             p.adjust.method = "none")
ngrams_holm_ttests <- pairwise.t.test(x = ngrams_all_longForm$value, 
                                             g = ngrams_all_longForm$form, 
                                             p.adjust.method = "holm")
ngrams_bonferroni_ttests <- pairwise.t.test(x = ngrams_all_longForm$value, 
                                             g = ngrams_all_longForm$form, 
                                             p.adjust.method = "bonferroni")
```

Next, show the p-values for the uncorrected t-tests of means, then the holm-corrected and bonferroni-corrected p-values. None of the t-tests are significant when using corrections of either type. If using uncorrected means (not recommended), the largest differences in means are for boy-man, person-man, girl-man, woman-man (in that order).

```{r, warning=FALSE, label = "analyses_ngrams_means_pvalues"}
round(ngrams_uncorrected_ttests$p.value, 3)
round(ngrams_holm_ttests$p.value, 3)
round(ngrams_bonferroni_ttests$p.value, 3)
```

```{r, eval = F, echo = F, label = "ngrams_ttest_tables_apa"}
# These tables are unnecessary for the website version

apa_table(ngrams_uncorrected_ttests$p.value,
          caption = "P-values of uncorrected t-tests comparing mean adjective ngrams frequency by person-word.",
          placement= "h")
apa_table(ngrams_holm_ttests$p.value,
          caption = "P-values of Holm-corrected t-tests comparing mean adjective ngrams frequency by person-word.",
          placement= "h")
apa_table(ngrams_bonferroni_ttests$p.value,
          caption = "P-values of Bonferroni-corrected t-tests comparing mean adjective ngrams frequency by person-word.",
          placement= "h")
```


### 2. Calculate z-scores

Now that we have compared the raw means in the prior step, we create a table of the zscores of the 10-year averages for each TDA + noun ngram. These are the data posted on Dataverse, as shown below.

```{r, warning=FALSE, label = "analyses_ngrams_zscores"}
ngrams_all_zscores <- tibble(
  TDA = ngrams_person$term,
  coded = ngrams_person$coded,
  person_zscore = ngrams_person$zscore,
  woman_zscore = ngrams_woman$zscore,
  man_zscore = ngrams_man$zscore,
  girl_zscore = ngrams_girl$zscore,
  boy_zscore = ngrams_boy$zscore
)
```

```{r, eval = T, echo = T, label = "save_ngrams_zscores"}
write_csv(ngrams_all_zscores, 
          file = here("data/ngrams/ngrams_all_zscores.csv"))
```

This csv file (above) has been posted publicly on Dataverse (see doi). All subsequent analyses of the ngrams data are based on this file, including the database of ngram estimates (see [here](https://pie-lab.github.io/tdafrequency/ngrams-frequency.html)).

*ADD DOI LINK TO THE SENTENCE ABOVE*

The following code clears the environment and loads the data directly from Dataverse.

*CHANGE THIS TO PULL THE ZSCORES FILE FROM DATAVERSE.*
```{r, echo = T, label = "load_ngrams_zscores"}
rm(list=ls())
ngrams_all_zscores <- read_csv(here("data/ngrams/ngrams_all_zscores.csv"))
```

```{r, eval = F, echo = T, label = "load_ngrams_zscores_dataverse"}
library(dataverse)
library(data.table)

Sys.setenv("DATAVERSE_SERVER" = "dataverse.harvard.edu")
writeBin(get_file("TDA_data_scored.tab", "doi:10.7910/DVN/5T80PF"), "TDA_data_scored.tab")
TDA_data_scored.tab <- fread("TDA_data_scored.tab", na.strings=getOption("<NA>","NA"))
data <- as.data.frame(TDA_data_scored.tab)
rm(TDA_data_scored.tab)
```


### 3. Correlations between the 5 TDA + noun vectors

```{r, warning=FALSE, label = "analyses_ngrams_cors"}
# drop the column of TDA labels
ngrams_zscores <- subset(ngrams_all_zscores, select = -c(TDA, coded))
cor_ngrams <- corr.test(ngrams_zscores,
                        use = "pairwise", 
                        method = "pearson", 
                        alpha = 0.05,
                        ci = TRUE)

cor_ngrams_ci <- tibble(
  noun1 = c("person", "person", "person", "person", "woman", 
             "woman", "woman", "man", "man", "girl"),
  noun2 = c("woman", "man", "girl", "boy", "man", 
             "girl", "boy", "girl", "boy", "boy"),
  lower_bound = cor_ngrams$ci$lower,
  r = cor_ngrams$ci$r,
  upper_bound = cor_ngrams$ci$upper,
  p_value = cor_ngrams$ci$p
)
```

```{r , echo = F, label = "ngrams_cor_tables_apa"}
cor_ngrams_ci <- as.data.frame(cor_ngrams_ci)
cor_ngrams_ci$p_value <- round(cor_ngrams_ci$p_value, 3)
cor_ngrams_ci$lower_bound <- round(cor_ngrams_ci$lower_bound, 3)
cor_ngrams_ci$r <- round(cor_ngrams_ci$r, 3)
cor_ngrams_ci$upper_bound <- round(cor_ngrams_ci$upper_bound, 3)

# apa_table(cor_ngrams$r,
#           caption = "Correlations between ngram person-words.",
#           placement= "h")
# apa_table(cor_ngrams_ci,
#           caption = "Correlations between ngram person-words, with confidence intervals.",
#           placement= "h")
```

The table below shows the correlations between noun pairs with the lower and upper bounds of the 95% confidence intervals.

```{r, warning=FALSE, echo = F, label = "analyses_ngrams_cors_cis"}
cor_ngrams_ci
```


### 4. Calculate the Ngrams frequency index

Here, we find the frequencies index by finding the average of the z-scores across all 5 TDA + noun pairs for each TDA *after* removing the max z-score for each TDA. In other words, find the average among all but the largest z-score for each TDA. This approach is used to reduce the skew introduced in a few cases where the pairing of a specific TDA + noun is part of a song, book, famous individual, etc.

Output from the following section of code is used to populate the ngram column of the [database of frequencies](https://pie-lab.github.io/tdafrequency/ngrams-frequency.html) provided on this website.

```{r, warning=FALSE, label = "analyses_ngrams_freq-index"}
bucket <- c()
for (j in 1:nrow(ngrams_zscores)) 
{
  vector_i <- c()
  vector_i <- unname(unlist(ngrams_zscores[j,]))
  vector_i <- vector_i[vector_i != max(vector_i, na.rm = TRUE)] #remove max zsc
  freq_val <- mean(vector_i, na.rm = TRUE)
  bucket[j] <- freq_val
}

ngrams_freq_index <- ngrams_zscores %>%
  mutate(
    freq_index = bucket
  ) 

ngrams_freq_index <- ngrams_freq_index %>%
  mutate(
    TDA = ngrams_all_zscores$TDA,
    freq_index = if_else(condition = is.nan(freq_index), 
                         true = as.double(NA), 
                         false = freq_index),
  ) %>%
    select(TDA, everything())
```

```{r , echo = F, label = "top_ngrams_table_apa"}
write_csv(ngrams_freq_index, 
          file = here("data/ngrams/ngrams_freq_index.csv"))

present_table1 <- ngrams_freq_index %>%
  arrange(desc(freq_index)) %>%
  select(TDA, freq_index)

# apa_table(present_table1[1:10,],
        # caption = "Top 10 adjectives with the highest frequency index.",
          # placement= "h")
```


# Correlation between search engine and ngram estimates

This is done by creating a large data frame with all the search engine and ngram estimates for each descriptor. Note that (1) the confidence intervals for some of the correlations involving ngram values are very wide due to large numbers of missing observations, and (2) there is a more nicely formatted table in the manuscript referenced at the top of this page.

```{r, warning=FALSE, R.options = list(width = 90), label = "serp_ngram_correlations"}
ngrams <- as.data.frame(ngrams_freq_index)[,c("person_zscore", "woman_zscore", "man_zscore", "girl_zscore", "boy_zscore", "freq_index")]
rownames(ngrams) <- as.data.frame(ngrams_freq_index)[,"TDA"]
colnames(ngrams) <- c("person_ngrams", "woman_ngrams", "man_ngrams", "girl_ngrams", "boy_ngrams", "index_ngrams")

serps_freq_index <- read_csv(here("data/serps/serps_freq_index.csv"))
serps <- as.data.frame(serps_freq_index)[,c("person_zscore", "woman_zscore", "man_zscore", "girl_zscore", "boy_zscore", "freq_index")]
rownames(serps) <- as.data.frame(serps_freq_index)[,"TDA"]
colnames(serps) <- c("person_serps", "woman_serps", "man_serps", "girl_serps", "boy_serps", "index_serps")

all <- data.frame(serps, ngrams)
all_cor <- corCi(all, plot = FALSE)
all_cor
```


# Comparison with Roivainen (2013)

As pre-registered, we evaluated the correlation between the frequency estimates presented here and the estimates reported in Roivainen (2013). This was done using z-scored versions of the raw counts provided by Roivainen (personal correspondence).

```{r, warning=FALSE, label = "roivainen_comparison"}
rm(list=ls())
roivainen <- read_csv(here("data/other/roivainen_comparison.csv"))

serps_freq_index <- read_csv(here("data/serps/serps_freq_index.csv"))
serps_freq <- as.data.frame(serps_freq_index[,c("person_zscore", "freq_index")])
rownames(serps_freq) <- serps_freq_index$TDA
roivainen_435_serps <- serps_freq[as.data.frame(roivainen)[,1],]
colnames(roivainen_435_serps) <- c("person_serps", "index_serps")

ngrams_freq_index <- read_csv(here("data/ngrams/ngrams_freq_index.csv"))
ngrams_freq <- as.data.frame(ngrams_freq_index[,c("person_zscore", "freq_index")])
rownames(ngrams_freq) <- ngrams_freq_index$TDA
roivainen_435_ngrams <- ngrams_freq[as.data.frame(roivainen)[,1],]
colnames(roivainen_435_ngrams) <- c("person_ngrams", "index_ngrams")

roivainen <- data.frame(roivainen[,"Rserps2012z"], roivainen_435_serps, roivainen[,"Rngrams2000z"], roivainen_435_ngrams)
roivainenCor <- corCi(roivainen, plot = FALSE)

roiCor_df <- data.frame(roivainenCor$ci[,c("low.e")], roivainenCor$means, roivainenCor$ci[,c("up.e", "p")])
colnames(roiCor_df) <- c("lowerCI", "r", "upperCI", "p_value")
roiCor_df <- roiCor_df[c("R2012-prsn_s", "R2012-indx_s", "R2000-prsn_n", "R2000-indx_n"),]
rownames(roiCor_df) <- c("serps_person2012z-serps_person2022z", "serps_person2012z-serps_freq_index2022", "ngrams_person2000z-ngrams_person2019z", "ngrams_person2000z-ngrams_freq_index2019")
round(roiCor_df,3)
```

```{r, eval = T, echo = T, label = "motschenbacher_tests"}
ngrams_gender_age <- as.data.frame(ngrams_freq_index)[, c("woman_zscore", "man_zscore", "girl_zscore", "boy_zscore")]-as.data.frame(ngrams_freq_index)[, c("freq_index")]
colnames(ngrams_gender_age) <- c("dev_woman", "dev_man", "dev_girl", "dev_boy")
rownames(ngrams_gender_age) <- as.data.frame(ngrams_freq_index)[, c("TDA")]

ngrams_dev_woman <- ngrams_gender_age[order(ngrams_gender_age$dev_woman),]
ngrams_dev_woman <- ngrams_dev_woman[!is.na(ngrams_dev_woman$dev_woman),]
head(ngrams_dev_woman, 10)
tail(ngrams_dev_woman, 10)

ngrams_dev_man <- ngrams_gender_age[order(ngrams_gender_age$dev_man),]
ngrams_dev_man <- ngrams_dev_man[!is.na(ngrams_dev_man$dev_man),]
head(ngrams_dev_man, 10)
tail(ngrams_dev_man, 10)

ngrams_dev_girl <- ngrams_gender_age[order(ngrams_gender_age$dev_girl),]
ngrams_dev_girl <- ngrams_dev_girl[!is.na(ngrams_dev_girl$dev_girl),]
head(ngrams_dev_girl, 10)
tail(ngrams_dev_girl, 10)

ngrams_dev_boy <- ngrams_gender_age[order(ngrams_gender_age$dev_boy),]
ngrams_dev_boy <- ngrams_dev_boy[!is.na(ngrams_dev_boy$dev_boy),]
head(ngrams_dev_boy, 10)
tail(ngrams_dev_boy, 10)

serps_gender_age <- as.data.frame(serps_freq_index)[, c("woman_zscore", "man_zscore", "girl_zscore", "boy_zscore")]-as.data.frame(serps_freq_index)[, c("freq_index")]
colnames(serps_gender_age) <- c("dev_woman", "dev_man", "dev_girl", "dev_boy")
rownames(serps_gender_age) <- as.data.frame(serps_freq_index)[, c("TDA")]

serps_dev_woman <- serps_gender_age[order(serps_gender_age$dev_woman),]
serps_dev_woman <- serps_dev_woman[!is.na(serps_dev_woman$dev_woman),]
head(serps_dev_woman, 10)
tail(serps_dev_woman, 10)

serps_dev_man <- serps_gender_age[order(serps_gender_age$dev_man),]
serps_dev_man <- serps_dev_man[!is.na(serps_dev_man$dev_man),]
head(serps_dev_man, 10)
tail(serps_dev_man, 10)

serps_dev_girl <- serps_gender_age[order(serps_gender_age$dev_girl),]
serps_dev_girl <- serps_dev_girl[!is.na(serps_dev_girl$dev_girl),]
head(serps_dev_girl, 10)
tail(serps_dev_girl, 10)

serps_dev_boy <- serps_gender_age[order(serps_gender_age$dev_boy),]
serps_dev_boy <- serps_dev_boy[!is.na(serps_dev_boy$dev_boy),]
head(serps_dev_boy, 10)
tail(serps_dev_boy, 10)
```
