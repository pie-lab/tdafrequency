---
title: "Analytic Code"
date: "Last updated `r Sys.Date()`"
output: 
  html_document:
    toc: TRUE
---

```{r, include = F}
knitr::opts_chunk$set(message = F, warning = F)
rm(list=ls())
```

<br>

# Prepare the environment

```{r, warning=FALSE, message=FALSE, label = "libraries_data"}
library(here) # for engaging with working environment
library(rio) # for importing excel files
library(psych) # for scoring multiple choice items
library(R.utils) # just for the insert() function
library(tidyverse) # for data cleaning and manipulation
library(matrixStats)
library(kableExtra)
library(apaTables)

options(scipen=999)
```

<br>

# Derive the search engine frequency estimates

<br> 

## Data loading and preparation

The csv files contain the raw data. These cannot be shared in raw form, but transformations of the raw data are publicly available on Dataverse (see the link below and on the home page). Here, we show how the raw data are loaded, for cleaning and description. Further down in the code, we show the data being saved into the format posted on Dataverse.

```{r, message = F, warning = F, eval = T, label = "load_raw_data_serps"}
serps_person <- read_csv(here("../../TDAfreqdata/SERPs/serps_rawdata_file_person.csv"))
serps_woman <- read_csv(here("../../TDAfreqdata/SERPs/serps_rawdata_file_woman.csv"))
serps_man <- read_csv(here("../../TDAfreqdata/SERPs/serps_rawdata_file_man.csv"))
serps_girl <- read_csv(here("../../TDAfreqdata/SERPs/serps_rawdata_file_girl.csv"))
serps_boy <- read_csv(here("../../TDAfreqdata/SERPs/serps_rawdata_file_boy.csv"))
```

Once loaded, the data are re-coded in the instances where empty results are automatically replaced with results for similarly spelled terms. See the manuscript for more description of this issue. Once cleaned, the counts from each raw data file are combined into a single data frame with all of the descriptor + noun pairings.

```{r, warning=FALSE, message=FALSE, label = "data-prep_serps"}
NOUNS_LIST <- c("person", "woman", "man", "girl", "boy")

serps_person <- serps_person %>%
  mutate(
    count = if_else(condition = type == "Empty showing fixed spelling results",
                    true = 0,
                    false = count)
  )

serps_woman <- serps_woman %>%
  mutate(
    count = if_else(condition = type == "Empty showing fixed spelling results",
                    true = 0,
                    false = count)
  )

serps_man <- serps_man %>%
  mutate(
    count = if_else(condition = type == "Empty showing fixed spelling results",
                    true = 0,
                    false = count)
  )

serps_girl <- serps_girl %>%
  mutate(
    count = if_else(condition = type == "Empty showing fixed spelling results",
                    true = 0,
                    false = count)
  )

serps_boy <- serps_boy %>%
  mutate(
    count = if_else(condition = type == "Empty showing fixed spelling results",
                    true = 0,
                    false = count)
  )

### RE-ORGANIZE SERPS DATASETS - COMBINE PERSON-WORD FORMS
serps_all <- tibble(
  TDA = serps_person$term,
  person = serps_person$count,
  woman = serps_woman$count,
  man = serps_man$count,
  girl = serps_girl$count,
  boy = serps_boy$count
)
serps_all <- subset(serps_all, TDA != "self-harming")

serps_all_onlyFreq <- serps_all %>%
  select(-TDA)
```

It's also necessary to fix special characters for many of the descriptors.

```{r, warning=FALSE, message=FALSE, label = "data-prep_serps_special_characters"}
# fix characters
serps_all$TDA <- sub("acharn√©", "achar", serps_all$TDA)
serps_all$TDA <- sub("b√™te", "bête", serps_all$TDA)
serps_all$TDA <- sub("blas\x8e", "blasé", serps_all$TDA)
serps_all$TDA <- sub("bont√©", "bonté", serps_all$TDA)
serps_all$TDA <- sub("bo√∂pis", "boöpis", serps_all$TDA)
serps_all$TDA <- sub("born√©", "borné", serps_all$TDA)
serps_all$TDA <- sub("d√©gag√©", "dégagé", serps_all$TDA)
serps_all$TDA <- sub("d√©pays√©", "dépaysé", serps_all$TDA)
serps_all$TDA <- sub("d√©sorient√©", "désorienté", serps_all$TDA)
serps_all$TDA <- sub("distingu√©", "distingué", serps_all$TDA)
serps_all$TDA <- sub("d√ºreresque", "düreresque", serps_all$TDA)
serps_all$TDA <- sub("√©clat", "éclat", serps_all$TDA)
serps_all$TDA <- sub("effar√©", "effaré", serps_all$TDA)
serps_all$TDA <- sub("√©l√©gante", "élégante", serps_all$TDA)
serps_all$TDA <- sub("√©lite", "élite", serps_all$TDA)
serps_all$TDA <- sub("ent√™t√©", "entêté", serps_all$TDA)
serps_all$TDA <- sub("espi√®gle", "espiègle", serps_all$TDA)
serps_all$TDA <- sub("fa√´rie", "faërie", serps_all$TDA)
serps_all$TDA <- sub("fain√©ant", "fainéant", serps_all$TDA)
serps_all$TDA <- sub("FALSE", "false", serps_all$TDA)
serps_all$TDA <- sub("outr√©", "outré", serps_all$TDA)
serps_all$TDA <- sub("pr√©cieuse", "précieuse", serps_all$TDA)
serps_all$TDA <- sub("r√©chauff√©", "réchauffé", serps_all$TDA)
serps_all$TDA <- sub("rou√©", "roué", serps_all$TDA)
serps_all$TDA <- sub("TRUE", "true", serps_all$TDA)
serps_all$TDA <- sub("unco√∂rdinated", "uncoördinated", serps_all$TDA)
serps_all$TDA <- sub("zo√∂id", "zoöid", serps_all$TDA)
serps_all$TDA <- sub("zo√∂philous", "zoöphilous", serps_all$TDA)
```

<br>

## Analyses

<br> 

### 1. Calculate overall means and compare differences using t-tests

```{r, warning=FALSE, "analyses_serps_means"}
serps_all_means <- c()
for (j in 1:ncol(serps_person))
{
  serps_all_means[j] <- mean(unname(unlist(serps_all_onlyFreq[,j])), na.rm = TRUE)
}
names(serps_all_means) <- NOUNS_LIST
serps_all_means

serps_all_longForm <- serps_all %>%
  gather(form, value, person:boy)
serps_uncorrected_ttests <- pairwise.t.test(x = serps_all_longForm$value, 
                                             g = serps_all_longForm$form, 
                                             p.adjust.method = "none")
serps_holm_ttests <- pairwise.t.test(x = serps_all_longForm$value, 
                                             g = serps_all_longForm$form, 
                                             p.adjust.method = "holm")
```

Next, show the p-values for the uncorrected t-tests of means, then the holm-corrected p-values. Only boy-girl and girl-woman are significant when using the holm-correction. If using uncorrected means (not recommended), boy-man and girl-person are also significant at *p* < .05.

```{r, warning=FALSE, label = "analyses_serps_means_pvalues"}
round(serps_uncorrected_ttests$p.value, 3)
round(serps_holm_ttests$p.value, 3)
```

```{r, eval = F, echo = F, label = "serps_ttest_tables_apa"}
apa_table(serps_uncorrected_ttests$p.value, caption = "P-values of uncorrected t-tests comparing mean descriptor SERPs count by person-word.", placement = "h")
apa_table(serps_holm_ttests$p.value, caption = "P-values of Holm-corrected t-tests comparing mean descriptor SERPs count by person-word.", placement = "h")
```

<br>

### 2. Calculate z-scores

Now that we have compared the raw means in the prior step, we create a table of the z-scores of the 10-year averages for each descriptor + noun ngram. These are the data posted on Dataverse, as shown below.

```{r, warning=FALSE, "analyses_serps_zscores"}
serps_all_zscores <- serps_all %>%
  mutate(
    TDA = serps_all$TDA,
    person_zscore = (person - mean(person, na.rm = TRUE))/sd(person, na.rm = TRUE),
    woman_zscore = (woman - mean(woman, na.rm = TRUE))/sd(woman, na.rm = TRUE),
    man_zscore = (man - mean(man, na.rm = TRUE))/sd(man, na.rm = TRUE),
    girl_zscore = (girl - mean(girl, na.rm = TRUE))/sd(girl, na.rm = TRUE),
    boy_zscore = (boy - mean(boy, na.rm = TRUE))/sd(boy, na.rm = TRUE)
  ) %>%
  select(TDA, person_zscore:boy_zscore)
```


```{r, eval = T, echo = T, label = "save_serps_zscores"}
write_csv(serps_all_zscores, 
          file = here("data/serps/serps_all_zscores.csv"))
```

This csv file (above) has been posted on Dataverse (see doi). All subsequent analyses of the search engine results data are based on this file, including the database of search engine estimates (see [here](https://pie-lab.github.io/tdafrequency/serps-frequency.html)).

*ADD DOI LINK TO THE SENTENCE ABOVE*

The following code clears the environment and loads the data directly from Dataverse.

*CHANGE THIS TO PULL THE ZSCORES FILE FROM DATAVERSE.*
```{r, echo = T, label = "load_serps_zscores"}
rm(list=ls())
serps_all_zscores <- read_csv(here("data/serps/serps_all_zscores.csv"))
```

```{r, eval = F, echo = T, label = "load_serps_zscores_dataverse"}
library(dataverse)
library(data.table)

Sys.setenv("DATAVERSE_SERVER" = "dataverse.harvard.edu")
writeBin(get_file("TDA_data_scored.tab", "doi:10.7910/DVN/5T80PF"), "TDA_data_scored.tab")
TDA_data_scored.tab <- fread("TDA_data_scored.tab", na.strings=getOption("<NA>","NA"))
data <- as.data.frame(TDA_data_scored.tab)
rm(TDA_data_scored.tab)
```

<br>

### 3. Calculate the search engine frequency index

Here, we find the frequencies index by finding the average of the z-scores across all 5 descriptor + noun pairs for each descriptor *after* removing the max z-score for each descriptor. In other words, find the average among all but the largest z-score for each descriptor. This approach is used to reduce the skew introduced in a few cases where the pairing of a specific descriptor + noun is part of a song, book, famous individual, etc.

Output from the following section of code is used to populate the serps column of the [database of frequencies](https://pie-lab.github.io/tdafrequency/serps-frequency.html) provided on this website.

```{r, warning=FALSE, label = "analyses_serps_freq-index"}
serps_zscores <- subset(serps_all_zscores, select = -c(TDA))

bucket <- c()
for (j in 1:nrow(serps_zscores)) 
{
  vector_i <- c()
  vector_i <- unname(unlist(serps_zscores[j,]))
  vector_i <- vector_i[vector_i != max(vector_i, na.rm = TRUE)]
  freq_val <- mean(vector_i, na.rm = TRUE)
  bucket[j] <- freq_val
}

serps_freq_index <- serps_zscores %>%
  mutate(
    TDA = serps_all_zscores$TDA,
    freq_index = bucket
  )  %>%
    select(TDA, everything())
```

```{r , echo = F, label = "top_serps_table_apa"}
write_csv(serps_freq_index, 
          file = here("data/serps/serps_freq_index.csv"))

# present_table2 <- serps_freq_index %>%
#   arrange(desc(freq_index)) %>%
#   select(TDA, freq_index)

#apa_table(present_table2[1:10,],
        #  caption = "Top 10 descriptors with the highest frequency index.",
        #  placement= "h")
```

<br>

### 4. Correlations between the 5 descriptor + noun vectors

The following code formats the data frame for the table.
```{r, warning=FALSE, label = "analyses_serps_cors"}
serps_cor_tab <- subset(serps_freq_index, select = -c(TDA))
colnames(serps_cor_tab) <- c("descriptor+person serps", "descriptor+woman serps", "descriptor+man serps", "descriptor+girl serps", "descriptor+boy serps", "frequency index serps")
```

The table below shows the correlations between descriptor + noun forms with the lower and upper bounds of the 95% confidence intervals. All the correlations are statistically significant but those involving +person are much lower than the rest. Among the other noun forms, woman-man and woman-girl are the strongest. Without exception, the highest correlations for each noun form is with the index, as expected given the overlap in content.

```{r, echo=F, warning=FALSE, label = "analyses_serps_cors_table"}
serps_cor_table = apa.cor.table(serps_cor_tab, show.sig.stars = FALSE, filename = "~/Downloads/serps_cortable.html")
 serps_cor_table$table.body %>%
   as.data.frame() %>%
   #remove mean and sd
   select(-M, -SD) %>%
   kable(booktabs = T,align = c("l", rep("c", 11)), table.attr = "style='width:60%;'",
         row.names = F) %>% kable_classic()
```

<br>

# Derive the books frequency estimates

## Data loading and preparation

The csv files contain the raw data. As with the search engine results, these cannot be shared in raw form, but transformations of the raw data are publicly available on Dataverse (see the link below and on the home page). Here, we show how the raw data are loaded, for cleaning and description. Further down in the code, we show the data being saved into the format available on Dataverse.

```{r, message = F, warning = F, eval = T, label = "load_raw_data"}
ngrams_person <- read_csv("../../TDAfreqdata/ngrams/ngrams_rawdata_file_person.csv")
ngrams_woman <- read_csv("../../TDAfreqdata/ngrams/ngrams_rawdata_file_woman.csv")
ngrams_man <- read_csv("../../TDAfreqdata/ngrams/ngrams_rawdata_file_man.csv")
ngrams_girl <- read_csv("../../TDAfreqdata/ngrams/ngrams_rawdata_file_girl.csv")
ngrams_boy <- read_csv("../../TDAfreqdata/ngrams/ngrams_rawdata_file_boy.csv")
```

Once loaded, we derive the means for each descriptor + noun form across the 10 year period from 2010 to 2019. These averages are then combined in a new data frame.

```{r, warning=FALSE, message=FALSE, label = "data-prep_ngrams"}
NOUNS_LIST <- c("person", "woman", "man", "girl", "boy")

### AVERAGE NGRAMS DATA ACROSS YEARS
select_vars <- c("freq.2010","freq.2011","freq.2012","freq.2013","freq.2014",
                            "freq.2015","freq.2016","freq.2017","freq.2018","freq.2019")

ngrams_person <- ngrams_person %>%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_woman <- ngrams_woman %>%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_man <- ngrams_man %>%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_girl <- ngrams_girl %>%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_boy <- ngrams_boy %>%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

### COMBINE INTO ONE TABLE

ngrams_all_avgfreq <- tibble(
  TDA = ngrams_person$term,
  freq_avg_person = ngrams_person$freq_avg_all_years,
  freq_avg_woman = ngrams_woman$freq_avg_all_years,
  freq_avg_man = ngrams_man$freq_avg_all_years,
  freq_avg_girl = ngrams_girl$freq_avg_all_years,
  freq_avg_boy = ngrams_boy$freq_avg_all_years
)
ngrams_all_avgfreq <- subset(ngrams_all_avgfreq, TDA != "self-harming")
```

It's also necessary to fix special characters for many of the descriptors.

```{r, warning=FALSE, message=FALSE, label = "data-prep_ngrams_special_characters"}
# fix characters
ngrams_all_avgfreq$TDA <- sub("acharn√©", "acharné", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("b√™te", "bête", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("blas\x8e", "blasé", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("bont√©", "bonté", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("bo√∂pis", "boöpis", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("born√©", "borné", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("d√©gag√©", "dégagé", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("d√©pays√©", "dépaysé", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("d√©sorient√©", "désorienté", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("distingu√©", "distingué", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("d√ºreresque", "düreresque", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("√©clat", "éclat", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("effar√©", "effaré", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("√©l√©gante", "élégante", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("√©lite", "élite", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("ent√™t√©", "entêté", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("espi√®gle", "espiègle", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("fa√´rie", "faërie", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("fain√©ant", "fainéant", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("FALSE", "false", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("outr√©", "outré", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("pr√©cieuse", "précieuse", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("r√©chauff√©", "réchauffé", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("rou√©", "roué", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("TRUE", "true", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("unco√∂rdinated", "uncoördinated", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("zo√∂id", "zoöid", ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA <- sub("zo√∂philous", "zoöphilous", ngrams_all_avgfreq$TDA)
```

<br>

## Analyses

<br> 

### 1. Calculate overall means and compare differences using t-tests

Calculate the overall means for each of the descriptor + noun vectors. In other words, find the means for all the descriptor + person ngrams, descriptor + man ngrams, woman, girl, and boy. Then compare the means with t-tests. This is repeated using the holm corrections.

```{r, warning=FALSE, label = "analyses_ngrams_means"}
# drop the column of TDA labels
ngrams_avgfreq <- subset(ngrams_all_avgfreq, select = -c(TDA))
means_vector <- c()
for (j in 1:ncol(ngrams_avgfreq))
{
  means_vector[j] <- mean( unname(unlist(ngrams_avgfreq[,j])), na.rm = TRUE)
}

names(means_vector) <- NOUNS_LIST
means_vector

ngrams_all_longForm <- ngrams_avgfreq %>%
  gather(form, value, freq_avg_person:freq_avg_boy)

ngrams_uncorrected_ttests <- pairwise.t.test(x = ngrams_all_longForm$value, 
                                             g = ngrams_all_longForm$form, 
                                             p.adjust.method = "none")
ngrams_holm_ttests <- pairwise.t.test(x = ngrams_all_longForm$value, 
                                             g = ngrams_all_longForm$form, 
                                             p.adjust.method = "holm")
```

Next, show the p-values for the uncorrected t-tests of means, then the holm-corrected p-values. None of the t-tests are significant when using the corrected p-values. If using uncorrected values (not recommended), the largest differences in means are for boy-man, person-man, girl-man, woman-man (in that order).

```{r, warning=FALSE, label = "analyses_ngrams_means_pvalues"}
round(ngrams_uncorrected_ttests$p.value, 3)
round(ngrams_holm_ttests$p.value, 3)
```

```{r, eval = F, echo = F, label = "ngrams_ttest_tables_apa"}
# These tables are unnecessary for the website version

apa_table(ngrams_uncorrected_ttests$p.value,
          caption = "P-values of uncorrected t-tests comparing mean descriptor ngrams frequency by person-word.",
          placement= "h")
apa_table(ngrams_holm_ttests$p.value,
          caption = "P-values of Holm-corrected t-tests comparing mean descriptor ngrams frequency by person-word.",
          placement= "h")
```

<br> 

### 2. Calculate z-scores

Now that we have compared the raw means in the prior step, we create a table of the z-scores of the 10-year averages for each descriptor + noun form. These are the data posted on Dataverse, as shown below.

```{r, warning=FALSE, label = "analyses_ngrams_zscores"}
ngrams_all_zscores <- tibble(
  TDA = ngrams_person$term,
  coded = ngrams_person$coded,
  person_zscore = ngrams_person$zscore,
  woman_zscore = ngrams_woman$zscore,
  man_zscore = ngrams_man$zscore,
  girl_zscore = ngrams_girl$zscore,
  boy_zscore = ngrams_boy$zscore
)
ngrams_all_zscores <- subset(ngrams_all_zscores, TDA != "self-harming")

```

```{r, eval = T, echo = T, label = "save_ngrams_zscores"}
write_csv(ngrams_all_zscores, 
          file = here("data/ngrams/ngrams_all_zscores.csv"))
```

This csv file (above) has been posted on Dataverse (see doi). All subsequent analyses of the books data are based on this file, including the database of books estimates (see [here](https://pie-lab.github.io/tdafrequency/books-frequency.html)).

*ADD DOI LINK TO THE SENTENCE ABOVE*

The following code clears the environment and loads the data directly from Dataverse.

*CHANGE THIS TO PULL THE ZSCORES FILE FROM DATAVERSE.*
```{r, echo = T, label = "load_ngrams_zscores"}
rm(list=ls())
ngrams_all_zscores <- read_csv(here("data/ngrams/ngrams_all_zscores.csv"))
```

```{r, eval = F, echo = T, label = "load_ngrams_zscores_dataverse"}
library(dataverse)
library(data.table)

Sys.setenv("DATAVERSE_SERVER" = "dataverse.harvard.edu")
writeBin(get_file("TDA_data_scored.tab", "doi:10.7910/DVN/5T80PF"), "TDA_data_scored.tab")
TDA_data_scored.tab <- fread("TDA_data_scored.tab", na.strings=getOption("<NA>","NA"))
data <- as.data.frame(TDA_data_scored.tab)
rm(TDA_data_scored.tab)
```

<br> 

### 3. Calculate the books frequency index

Here, we find the frequencies index by finding the average of the z-scores across all 5 descriptor + noun pairs for each descriptor *after* removing the max z-score for each descriptor. In other words, find the average among all but the largest z-score for each descriptor. This approach is used to reduce the skew introduced in a few cases where the pairing of a specific descriptor + noun is part of a song, book, famous individual, etc.

Output from the following section of code is used to populate the ngram column of the [database of frequencies](https://pie-lab.github.io/tdafrequency/books-frequency.html) provided on this website.

```{r, warning=FALSE, label = "analyses_ngrams_freq-index"}
# drop the column of TDA labels
ngrams_zscores <- subset(ngrams_all_zscores, select = -c(TDA, coded))

bucket <- c()
for (j in 1:nrow(ngrams_zscores)) 
{
  vector_i <- c()
  vector_i <- unname(unlist(ngrams_zscores[j,]))
  vector_i <- vector_i[vector_i != max(vector_i, na.rm = TRUE)] #remove max zsc
  freq_val <- mean(vector_i, na.rm = TRUE)
  bucket[j] <- freq_val
}

ngrams_freq_index <- ngrams_zscores %>%
  mutate(
    freq_index = bucket
  ) 

ngrams_freq_index <- ngrams_freq_index %>%
  mutate(
    TDA = ngrams_all_zscores$TDA,
    freq_index = if_else(condition = is.nan(freq_index), 
                         true = as.double(NA), 
                         false = freq_index),
  ) %>%
    select(TDA, everything())
```

```{r , echo = F, label = "top_ngrams_table_apa"}
write_csv(ngrams_freq_index, 
          file = here("data/ngrams/ngrams_freq_index.csv"))

# present_table1 <- ngrams_freq_index %>%
#   arrange(desc(freq_index)) %>%
#   select(TDA, freq_index)

# apa_table(present_table1[1:10,],
        # caption = "Top 10 descriptors with the highest frequency index.",
          # placement= "h")
```

<br>

### 4. Correlations between the 5 descriptor + noun vectors

The following code formats the data frame for the table.

```{r, warning=FALSE, label = "analyses_ngrams_cors"}
ngrams_cor_tab <- subset(ngrams_freq_index, select = -c(TDA))
colnames(ngrams_cor_tab) <- c("descriptor+person books", "descriptor+woman books", "descriptor+man books", "descriptor+girl books", "descriptor+boy books", "frequency index books")
```

The table below shows the correlations between descriptor + noun forms with the lower and upper bounds of the 95% confidence intervals. As with the search engine results, all the correlations are statistically significant, and those involving +person are lower than the rest (in this case the difference is less pronounced). Note that the woman-man and girl-boy correlations are nearly perfect.

```{r, echo=F, warning=FALSE, label = "analyses_ngrams_cors_table"}
ngrams_cor_table = apa.cor.table(ngrams_cor_tab, show.sig.stars = FALSE, filename = "~/Downloads/ngrams_cortable.html")
 ngrams_cor_table$table.body %>%
   as.data.frame() %>%
   #remove mean and sd
   select(-M, -SD) %>%
   kable(booktabs = T,align = c("l", rep("c", 11)), table.attr = "style='width:60%;'",
         row.names = F) %>% kable_classic()
```

<br>

# Correlation between search engine and books estimates

This is done by creating a large data frame with all the search engine and books estimates for each descriptor. Note that this analysis overlaps with the correlational analyses previously reported within type, but it's easier to see it all in one table

```{r, warning=FALSE, R.options = list(width = 90), label = "serp_ngram_correlations"}
ngrams <- as.data.frame(ngrams_freq_index)[,c("person_zscore", "woman_zscore", "man_zscore", "girl_zscore", "boy_zscore", "freq_index")]
rownames(ngrams) <- as.data.frame(ngrams_freq_index)[,"TDA"]
colnames(ngrams) <- c("person_books", "woman_books", "man_books", "girl_books", "boy_books", "index_books")

serps_freq_index <- read_csv(here("data/serps/serps_freq_index.csv"))
serps <- as.data.frame(serps_freq_index)[,c("person_zscore", "woman_zscore", "man_zscore", "girl_zscore", "boy_zscore", "freq_index")]
rownames(serps) <- as.data.frame(serps_freq_index)[,"TDA"]
colnames(serps) <- c("person_serps", "woman_serps", "man_serps", "girl_serps", "boy_serps", "index_serps")

all <- data.frame(serps, ngrams)
```

The table below shows the correlations among all the search engine and books forms. Focusing only on the search engine-books correlations: the matched noun forms are strong for woman-woman, man-man, and boy-boy, but much less strong for girl-girl and person-person. Similarly, the indices are highly correlated across the two types, though there is considerable variability across the noun types by form. Some noun forms are more highly correlated with unmatched nouns across form --- the search engine results for girl is more highly correlated with the books results for woman, man, and boy than with the books results for girl.

```{r echo=F, results = 'asis', label ="giantcortable"}
library(apaTables)
all_cor_tab = apa.cor.table(all, show.sig.stars = FALSE, filename = "~/Downloads/cortable.html")
 all_cor_tab$table.body %>%
   as.data.frame() %>% 
   #remove mean annd sd
   select(-M, -SD) %>% 
   kable(booktabs = T,align = c("l", rep("c", 11)), 
         row.names = F) %>% kable_classic()
```

<br>

# Comparison with Roivainen (2013)

Next, we evaluated the correlation between the frequency estimates presented here and the estimates reported in Roivainen (2013). This was done using z-scored versions of the raw counts provided by Roivainen (personal correspondence).

```{r, warning=FALSE, label = "roivainen_comparison"}
#rm(list=ls())
roivainen <- read_csv(here("data/other/roivainen_comparison.csv"))
roivainen_435 <- data.frame(all[as.data.frame(roivainen)[,1],c("person_serps", "person_books")], roivainen[,c("roi_person_serps","roi_person_books")])
```

```{r echo=F, results = 'asis', label ="roivainencortable"}
library(apaTables)
roi_cor_tab = apa.cor.table(roivainen_435, show.sig.stars = FALSE, filename = "~/Downloads/cortable.html")
 roi_cor_tab$table.body %>%
   as.data.frame() %>% 
   #remove mean annd sd
   select(-M, -SD) %>% 
   kable(booktabs = T,align = c("l", rep("c", 11)), table.attr = "style='width:50%;'", 
         row.names = F) %>% kable_classic()
```

<br>

# Distinctive descriptors for each noun form

For each of the age- and gender-identity-specific nouns, we evaluated the most distinctive descriptors by ranking them according to the deviation from the frequency index for each type. In other words, we sorted by the difference between the z-score for each descriptor + noun form and the frequency index value for the same descriptor. Note that this is quite different from the most frequently used descriptors overall. To clarify that point, we show those first. These are the most frequent search engine results overall.

```{r, eval = T, echo = F, label = "motschenbacher_tests_allserps"}
freqs <- as.data.frame(all)[, c("index_serps", "index_books")]
freqs_serps <- freqs[order(freqs$index_serps, decreasing = T),]
freqs_serps <- freqs_serps[!is.na(freqs_serps$index_serps),]
rownames(head(freqs_serps))
```

And these are the most frequent books results overall.

```{r, eval = T, echo = F, label = "motschenbacher_tests_allbooks"}
freqs_books <- freqs[order(freqs$index_books, decreasing = T),]
freqs_books <- freqs_books[!is.na(freqs_books$index_books),]
rownames(head(freqs_books))
```

The following analyses looking at the distinctiveness of each noun form is based on findings reported in Motschenbacher and Roivainen (2020). These results may provide some indication of the extent to which the different types of results (search engine vs books) reflect stereotype bias. The original hypotheses for these analyses were not very specific. We initially expected to consider the most distinctive terms in both directions --- those descriptors used *most* frequently relative to other noun forms and those descriptors used *least* frequently. However, the data do not support evaluating the least frequently used descriptors because many descriptors have missing data (i.e., they were never used in the books or did not show up in search engine results). Only the most frequently used descriptors relative to other noun forms are shown below. 

The most frequent books results for descriptor + woman: 

```{r, eval = T, echo = F, label = "motschenbacher_tests_ngrams_woman"}
ngrams_gender_age <- as.data.frame(ngrams_freq_index)[, c("woman_zscore", "man_zscore", "girl_zscore", "boy_zscore")]-as.data.frame(ngrams_freq_index)[, c("freq_index")]
colnames(ngrams_gender_age) <- c("dev_woman", "dev_man", "dev_girl", "dev_boy")
rownames(ngrams_gender_age) <- as.data.frame(ngrams_freq_index)[, c("TDA")]

ngrams_dev_woman <- ngrams_gender_age[order(ngrams_gender_age$dev_woman, decreasing = T),]
ngrams_dev_woman <- ngrams_dev_woman[!is.na(ngrams_dev_woman$dev_woman),]
rownames(head(ngrams_dev_woman, 5))
```

The most frequent books results for descriptor + man: 

```{r, eval = T, echo = F, label = "motschenbacher_tests_ngrams_man"}
ngrams_dev_man <- ngrams_gender_age[order(ngrams_gender_age$dev_man, decreasing = T),]
ngrams_dev_man <- ngrams_dev_man[!is.na(ngrams_dev_man$dev_man),]
rownames(head(ngrams_dev_man, 5))
```

The most frequent books results for descriptor + girl: 

```{r, eval = T, echo = F, label = "motschenbacher_tests_ngrams_girl"}
ngrams_dev_girl <- ngrams_gender_age[order(ngrams_gender_age$dev_girl, decreasing = T),]
ngrams_dev_girl <- ngrams_dev_girl[!is.na(ngrams_dev_girl$dev_girl),]
rownames(head(ngrams_dev_girl, 5))
```

The most frequent books results for descriptor + boy: 

```{r, eval = T, echo = F, label = "motschenbacher_tests_ngrams_boy"}
ngrams_dev_boy <- ngrams_gender_age[order(ngrams_gender_age$dev_boy, decreasing = T),]
ngrams_dev_boy <- ngrams_dev_boy[!is.na(ngrams_dev_boy$dev_boy),]
rownames(head(ngrams_dev_boy, 5))
```

The most frequent search engine results for descriptor + woman: 

```{r, eval = T, echo = F, label = "motschenbacher_tests_serps_woman"}
serps_gender_age <- as.data.frame(serps_freq_index)[, c("woman_zscore", "man_zscore", "girl_zscore", "boy_zscore")]-as.data.frame(serps_freq_index)[, c("freq_index")]
colnames(serps_gender_age) <- c("dev_woman", "dev_man", "dev_girl", "dev_boy")
rownames(serps_gender_age) <- as.data.frame(serps_freq_index)[, c("TDA")]

serps_dev_woman <- serps_gender_age[order(serps_gender_age$dev_woman, decreasing = T),]
serps_dev_woman <- serps_dev_woman[!is.na(serps_dev_woman$dev_woman),]
rownames(head(serps_dev_woman, 5))
```

The most frequent search engine results for descriptor + man: 

```{r, eval = T, echo = F, label = "motschenbacher_tests_serps_man"}
serps_dev_man <- serps_gender_age[order(serps_gender_age$dev_man, decreasing = T),]
serps_dev_man <- serps_dev_man[!is.na(serps_dev_man$dev_man),]
rownames(head(serps_dev_man, 5))
```

The most frequent search engine results for descriptor + girl: 

```{r, eval = T, echo = F, label = "motschenbacher_tests_serps_girl"}
serps_dev_girl <- serps_gender_age[order(serps_gender_age$dev_girl, decreasing = T),]
serps_dev_girl <- serps_dev_girl[!is.na(serps_dev_girl$dev_girl),]
rownames(head(serps_dev_girl, 5))
```

The most frequent search engine results for descriptor + boy: 

```{r, eval = T, echo = F, label = "motschenbacher_tests_serps_boy"}
serps_dev_boy <- serps_gender_age[order(serps_gender_age$dev_boy, decreasing = T),]
serps_dev_boy <- serps_dev_boy[!is.na(serps_dev_boy$dev_boy),]
rownames(head(serps_dev_boy, 5))
```

These comparisons demonstrate a few points worth noting. Above all, most of the terms are specifications of demographic attributes --- young, old, black, white, big, little, small. Very few relate to psychological attributes. This point underscores the primary motivation for this work: the characterization of this large pool of descriptors is intended to provide an additional source of data for identifying a justifiably comprehensive listing of psychological trait descriptors (especially personality-relevant terms), but the list is clearly over-inclusive. This was known from the outset, but the next step is to combine these data with other sources of information and pare the list down to a more relevant subset. A separate point is that the female nouns are more related to physical attributes than the male traits; all of the female noun forms included the descriptor "beautiful" among the top 5. 

**[say something more here]**

Finally, the lists are generally consistent across the two types, at least among the most consistent terms. 

