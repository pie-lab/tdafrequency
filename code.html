<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Analytic Code</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">TDA</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="serps-frequency.html">Estimates based on Search Engine Results</a>
</li>
<li>
  <a href="ngrams-frequency.html">Estimates based on Books Results</a>
</li>
<li>
  <a href="code.html">Code</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://psyarxiv.com">
    <span class="fa fa-file"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/pie-lab/tdafrequency">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Analytic Code</h1>
<h4 class="date">Last updated 2022-04-20</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#prepare-the-environment">Prepare the environment</a></li>
<li><a href="#derive-the-search-engine-frequency-estimates">Derive the search engine frequency estimates</a>
<ul>
<li><a href="#data-loading-and-preparation">Data loading and preparation</a>
<ul>
<li><a href="#calculate-overall-means-and-compare-differences-using-t-tests">1. Calculate overall means and compare differences using t-tests</a></li>
<li><a href="#calculate-z-scores">2. Calculate z-scores</a></li>
<li><a href="#correlations-between-the-5-tda-noun-vectors">3. Correlations between the 5 TDA + noun vectors</a></li>
<li><a href="#calculate-the-search-engine-frequency-index">4. Calculate the search engine frequency index</a></li>
</ul></li>
</ul></li>
<li><a href="#derive-the-ngram-frequency-estimates">Derive the ngram frequency estimates</a>
<ul>
<li><a href="#data-loading-and-preparation-1">Data loading and preparation</a></li>
<li><a href="#analyses">Analyses</a>
<ul>
<li><a href="#calculate-overall-means-and-compare-differences-using-t-tests-1">1. Calculate overall means and compare differences using t-tests</a></li>
<li><a href="#calculate-z-scores-1">2. Calculate z-scores</a></li>
<li><a href="#correlations-between-the-5-tda-noun-vectors-1">3. Correlations between the 5 TDA + noun vectors</a></li>
<li><a href="#calculate-the-ngrams-frequency-index">4. Calculate the Ngrams frequency index</a></li>
</ul></li>
</ul></li>
<li><a href="#correlation-between-search-engine-and-ngram-estimates">Correlation between search engine and ngram estimates</a></li>
<li><a href="#comparison-with-roivainen-2013">Comparison with Roivainen (2013)</a></li>
</ul>
</div>

<div id="prepare-the-environment" class="section level1">
<h1>Prepare the environment</h1>
<pre class="r"><code>library(here) # for engaging with working environment
library(rio) # for importing excel files
library(psych) # for scoring multiple choice items
library(R.utils) # just for the insert() function
library(tidyverse) # for data cleaning and manipulation
library(matrixStats)
library(kableExtra)

options(scipen=999)</code></pre>
</div>
<div id="derive-the-search-engine-frequency-estimates" class="section level1">
<h1>Derive the search engine frequency estimates</h1>
<div id="data-loading-and-preparation" class="section level2">
<h2>Data loading and preparation</h2>
<p>The csv files contain the raw data. These cannot be shared in raw form, but transformations of the raw data are publicly available on Dataverse (see the link below and on the home page). Here, we show how the raw data are loaded, for cleaning and description. Further down in the code, we show the data being saved into the format posted on Dataverse.</p>
<pre class="r"><code>serps_person &lt;- read_csv(here(&quot;../../TDAfreqdata/SERPs/serps_rawdata_file_person.csv&quot;))
serps_woman &lt;- read_csv(here(&quot;../../TDAfreqdata/SERPs/serps_rawdata_file_woman.csv&quot;))
serps_man &lt;- read_csv(here(&quot;../../TDAfreqdata/SERPs/serps_rawdata_file_man.csv&quot;))
serps_girl &lt;- read_csv(here(&quot;../../TDAfreqdata/SERPs/serps_rawdata_file_girl.csv&quot;))
serps_boy &lt;- read_csv(here(&quot;../../TDAfreqdata/SERPs/serps_rawdata_file_boy.csv&quot;))</code></pre>
<p>Once loaded, the data are re-coded in the instances where empty results are automatically replaced with results for similarly spelled terms. See the manuscript for more description of this issue. Once cleaned, the counts from each raw data file are combined into a single data frame with all of the TDA + noun pairings.</p>
<pre class="r"><code>NOUNS_LIST &lt;- c(&quot;person&quot;, &quot;woman&quot;, &quot;man&quot;, &quot;girl&quot;, &quot;boy&quot;)

serps_person &lt;- serps_person %&gt;%
  mutate(
    count = if_else(condition = type == &quot;Empty showing fixed spelling results&quot;,
                    true = 0,
                    false = count)
  )

serps_woman &lt;- serps_woman %&gt;%
  mutate(
    count = if_else(condition = type == &quot;Empty showing fixed spelling results&quot;,
                    true = 0,
                    false = count)
  )

serps_man &lt;- serps_man %&gt;%
  mutate(
    count = if_else(condition = type == &quot;Empty showing fixed spelling results&quot;,
                    true = 0,
                    false = count)
  )

serps_girl &lt;- serps_girl %&gt;%
  mutate(
    count = if_else(condition = type == &quot;Empty showing fixed spelling results&quot;,
                    true = 0,
                    false = count)
  )

serps_boy &lt;- serps_boy %&gt;%
  mutate(
    count = if_else(condition = type == &quot;Empty showing fixed spelling results&quot;,
                    true = 0,
                    false = count)
  )

### RE-ORGANIZE SERPS DATASETS - COMBINE PERSON-WORD FORMS
serps_all &lt;- tibble(
  TDA = serps_person$term,
  person = serps_person$count,
  woman = serps_woman$count,
  man = serps_man$count,
  girl = serps_girl$count,
  boy = serps_boy$count
)
serps_all &lt;- subset(serps_all, TDA != &quot;self-harming&quot;)

serps_all_onlyFreq &lt;- serps_all %&gt;%
  select(-TDA)</code></pre>
<p>It’s also necessary to fix special characters for many of the descriptors.</p>
<pre class="r"><code># fix characters
serps_all$TDA &lt;- sub(&quot;acharn√©&quot;, &quot;achar&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;b√™te&quot;, &quot;bête&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;blas\x8e&quot;, &quot;blasé&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;bont√©&quot;, &quot;bonté&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;bo√∂pis&quot;, &quot;boöpis&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;born√©&quot;, &quot;borné&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;d√©gag√©&quot;, &quot;dégagé&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;d√©pays√©&quot;, &quot;dépaysé&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;d√©sorient√©&quot;, &quot;désorienté&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;distingu√©&quot;, &quot;distingué&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;d√ºreresque&quot;, &quot;düreresque&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;√©clat&quot;, &quot;éclat&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;effar√©&quot;, &quot;effaré&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;√©l√©gante&quot;, &quot;élégante&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;√©lite&quot;, &quot;élite&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;ent√™t√©&quot;, &quot;entêté&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;espi√®gle&quot;, &quot;espiègle&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;fa√´rie&quot;, &quot;faërie&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;fain√©ant&quot;, &quot;fainéant&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;FALSE&quot;, &quot;false&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;outr√©&quot;, &quot;outré&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;pr√©cieuse&quot;, &quot;précieuse&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;r√©chauff√©&quot;, &quot;réchauffé&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;rou√©&quot;, &quot;roué&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;TRUE&quot;, &quot;true&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;unco√∂rdinated&quot;, &quot;uncoördinated&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;zo√∂id&quot;, &quot;zoöid&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;zo√∂philous&quot;, &quot;zoöphilous&quot;, serps_all$TDA)</code></pre>
<div id="calculate-overall-means-and-compare-differences-using-t-tests" class="section level3">
<h3>1. Calculate overall means and compare differences using t-tests</h3>
<pre class="r"><code>serps_all_means &lt;- c()
for (j in 1:ncol(serps_person))
{
  serps_all_means[j] &lt;- mean(unname(unlist(serps_all_onlyFreq[,j])), na.rm = TRUE)
}
names(serps_all_means) &lt;- NOUNS_LIST
serps_all_means</code></pre>
<pre><code>##   person    woman      man     girl      boy 
## 153750.6 126884.4 196866.7 276353.7  92631.9</code></pre>
<pre class="r"><code>serps_all_longForm &lt;- serps_all %&gt;%
  gather(form, value, person:boy)
serps_uncorrected_ttests &lt;- pairwise.t.test(x = serps_all_longForm$value, 
                                             g = serps_all_longForm$form, 
                                             p.adjust.method = &quot;none&quot;)
serps_holm_ttests &lt;- pairwise.t.test(x = serps_all_longForm$value, 
                                             g = serps_all_longForm$form, 
                                             p.adjust.method = &quot;holm&quot;)</code></pre>
<p>Next, show the p-values for the uncorrected t-tests of means, then the holm-corrected p-values. None of the t-tests are significant when using corrections of either type. If using uncorrected means (not recommended), the only significant difference in means is for girl-woman; the p-value for girl-person is just above the significance threshold at p&gt;.05.</p>
<pre class="r"><code>round(serps_uncorrected_ttests$p.value, 3)</code></pre>
<pre><code>##          boy  girl   man person
## girl   0.000    NA    NA     NA
## man    0.037 0.111    NA     NA
## person 0.221 0.014 0.388     NA
## woman  0.493 0.003 0.161  0.591</code></pre>
<pre class="r"><code>round(serps_holm_ttests$p.value, 3)</code></pre>
<pre><code>##          boy  girl   man person
## girl   0.002    NA    NA     NA
## man    0.258 0.668    NA     NA
## person 0.884 0.113 1.000     NA
## woman  1.000 0.025 0.805      1</code></pre>
</div>
<div id="calculate-z-scores" class="section level3">
<h3>2. Calculate z-scores</h3>
<p>Now that we have compared the raw means in the prior step, we create a table of the zscores of the 10-year averages for each TDA + noun ngram. These are the data posted on Dataverse, as shown below.</p>
<pre class="r"><code>serps_all_zscores &lt;- serps_all %&gt;%
  mutate(
    TDA = serps_all$TDA,
    person_zscore = (person - mean(person, na.rm = TRUE))/sd(person, na.rm = TRUE),
    woman_zscore = (woman - mean(woman, na.rm = TRUE))/sd(woman, na.rm = TRUE),
    man_zscore = (man - mean(man, na.rm = TRUE))/sd(man, na.rm = TRUE),
    girl_zscore = (girl - mean(girl, na.rm = TRUE))/sd(girl, na.rm = TRUE),
    boy_zscore = (boy - mean(boy, na.rm = TRUE))/sd(boy, na.rm = TRUE)
  ) %&gt;%
  select(TDA, person_zscore:boy_zscore)</code></pre>
<pre class="r"><code>write_csv(serps_all_zscores, 
          file = here(&quot;data/serps/serps_all_zscores.csv&quot;))</code></pre>
<p>This csv file (above) has been posted publicly on Dataverse (see doi). All subsequent analyses of the search engine results data are based on this file, including the database of search engine estimates (see <a href="https://pie-lab.github.io/tdafrequency/serps-frequency.html">here</a>).</p>
<p><em>ADD DOI LINK TO THE SENTENCE ABOVE</em></p>
<p>The following code clears the environment and loads the data directly from Dataverse.</p>
<p><em>CHANGE THIS TO PULL THE ZSCORES FILE FROM DATAVERSE.</em></p>
<pre class="r"><code>rm(list=ls())
serps_all_zscores &lt;- read_csv(here(&quot;data/serps/serps_all_zscores.csv&quot;))</code></pre>
<pre class="r"><code>library(dataverse)
library(data.table)

Sys.setenv(&quot;DATAVERSE_SERVER&quot; = &quot;dataverse.harvard.edu&quot;)
writeBin(get_file(&quot;TDA_data_scored.tab&quot;, &quot;doi:10.7910/DVN/5T80PF&quot;), &quot;TDA_data_scored.tab&quot;)
TDA_data_scored.tab &lt;- fread(&quot;TDA_data_scored.tab&quot;, na.strings=getOption(&quot;&lt;NA&gt;&quot;,&quot;NA&quot;))
data &lt;- as.data.frame(TDA_data_scored.tab)
rm(TDA_data_scored.tab)</code></pre>
</div>
<div id="correlations-between-the-5-tda-noun-vectors" class="section level3">
<h3>3. Correlations between the 5 TDA + noun vectors</h3>
<p>Note that there is a more nicely formatted table in the manuscript referenced at the top of this page.</p>
<pre class="r"><code>serps_zscores &lt;- subset(serps_all_zscores, select = -c(TDA))
cor_table_serps &lt;- corr.test(serps_zscores, 
                                    use = &quot;pairwise&quot;,
                                    method = &quot;pearson&quot;,
                                    alpha = .05,
                                    ci = TRUE)

cor_serps_ci &lt;- tibble(
  group1 = c(&quot;person&quot;, &quot;person&quot;, &quot;person&quot;, &quot;person&quot;, &quot;woman&quot;, 
             &quot;woman&quot;, &quot;woman&quot;, &quot;man&quot;, &quot;man&quot;, &quot;girl&quot;),
  group2 = c(&quot;woman&quot;, &quot;man&quot;, &quot;girl&quot;, &quot;boy&quot;, &quot;man&quot;, 
             &quot;girl&quot;, &quot;boy&quot;, &quot;girl&quot;, &quot;boy&quot;, &quot;boy&quot;),
  lower_bound = cor_table_serps$ci.adj$lower,
  r = cor_table_serps$ci$r,
  upper_bound = cor_table_serps$ci.adj$upper,
  p_value = cor_table_serps$ci2$p
)</code></pre>
<p>The table below shows the correlations between noun pairs with the lower and upper bounds of the 95% confidence intervals.</p>
<pre><code>##    group1 group2 lower_bound     r upper_bound p_value
## 1  person  woman       0.045 0.063       0.082       0
## 2  person    man       0.020 0.037       0.055       0
## 3  person   girl       0.021 0.037       0.054       0
## 4  person    boy       0.017 0.032       0.046       0
## 5   woman    man       0.698 0.708       0.719       0
## 6   woman   girl       0.632 0.645       0.656       0
## 7   woman    boy       0.494 0.508       0.523       0
## 8     man   girl       0.517 0.532       0.546       0
## 9     man    boy       0.363 0.380       0.396       0
## 10   girl    boy       0.569 0.583       0.596       0</code></pre>
</div>
<div id="calculate-the-search-engine-frequency-index" class="section level3">
<h3>4. Calculate the search engine frequency index</h3>
<p>Here, we find the frequencies index by finding the average of the z-scores across all 5 TDA + noun pairs for each TDA <em>after</em> removing the max z-score for each TDA. In other words, find the average among all but the largest z-score for each TDA. This approach is used to reduce the skew introduced in a few cases where the pairing of a specific TDA + noun is part of a song, book, famous individual, etc.</p>
<p>Output from the following section of code is used to populate the serps column of the <a href="https://pie-lab.github.io/tdafrequency/serps-frequency.html">database of frequencies</a> provided on this website.</p>
<pre class="r"><code>bucket &lt;- c()
for (j in 1:nrow(serps_zscores)) 
{
  vector_i &lt;- c()
  vector_i &lt;- unname(unlist(serps_zscores[j,]))
  vector_i &lt;- vector_i[vector_i != max(vector_i, na.rm = TRUE)]
  freq_val &lt;- mean(vector_i, na.rm = TRUE)
  bucket[j] &lt;- freq_val
}

serps_freq_index &lt;- serps_zscores %&gt;%
  mutate(
    TDA = serps_all_zscores$TDA,
    freq_index = bucket
  )  %&gt;%
    select(TDA, everything())</code></pre>
</div>
</div>
</div>
<div id="derive-the-ngram-frequency-estimates" class="section level1">
<h1>Derive the ngram frequency estimates</h1>
<div id="data-loading-and-preparation-1" class="section level2">
<h2>Data loading and preparation</h2>
<p>The csv files contain the raw data. As with the search engine results, these cannot be shared in raw form, but transformations of the raw data are publicly available on Dataverse (see the link below and on the home page). Here, we show how the raw data are loaded, for cleaning and description. Further down in the code, we show the data being saved into the format available on Dataverse.</p>
<pre class="r"><code>ngrams_person &lt;- read_csv(&quot;../../TDAfreqdata/ngrams/ngrams_rawdata_file_person.csv&quot;)
ngrams_woman &lt;- read_csv(&quot;../../TDAfreqdata/ngrams/ngrams_rawdata_file_woman.csv&quot;)
ngrams_man &lt;- read_csv(&quot;../../TDAfreqdata/ngrams/ngrams_rawdata_file_man.csv&quot;)
ngrams_girl &lt;- read_csv(&quot;../../TDAfreqdata/ngrams/ngrams_rawdata_file_girl.csv&quot;)
ngrams_boy &lt;- read_csv(&quot;../../TDAfreqdata/ngrams/ngrams_rawdata_file_boy.csv&quot;)</code></pre>
<p>Once loaded, we derive the means for each term + noun ngram across the 10 year period from 2010 to 2019. These averages are then combined in a new data frame.</p>
<pre class="r"><code>NOUNS_LIST &lt;- c(&quot;person&quot;, &quot;woman&quot;, &quot;man&quot;, &quot;girl&quot;, &quot;boy&quot;)

### AVERAGE NGRAMS DATA ACROSS YEARS
select_vars &lt;- c(&quot;freq.2010&quot;,&quot;freq.2011&quot;,&quot;freq.2012&quot;,&quot;freq.2013&quot;,&quot;freq.2014&quot;,
                            &quot;freq.2015&quot;,&quot;freq.2016&quot;,&quot;freq.2017&quot;,&quot;freq.2018&quot;,&quot;freq.2019&quot;)

ngrams_person &lt;- ngrams_person %&gt;%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_woman &lt;- ngrams_woman %&gt;%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_man &lt;- ngrams_man %&gt;%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_girl &lt;- ngrams_girl %&gt;%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_boy &lt;- ngrams_boy %&gt;%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

### COMBINE INTO ONE TABLE

ngrams_all_avgfreq &lt;- tibble(
  TDA = ngrams_person$term,
  freq_avg_person = ngrams_person$freq_avg_all_years,
  freq_avg_woman = ngrams_woman$freq_avg_all_years,
  freq_avg_man = ngrams_man$freq_avg_all_years,
  freq_avg_girl = ngrams_girl$freq_avg_all_years,
  freq_avg_boy = ngrams_boy$freq_avg_all_years
)
ngrams_all_avgfreq &lt;- subset(ngrams_all_avgfreq, TDA != &quot;self-harming&quot;)</code></pre>
<p>It’s also necessary to fix special characters for many of the descriptors.</p>
<pre class="r"><code># fix characters
ngrams_all_avgfreq$TDA &lt;- sub(&quot;acharn√©&quot;, &quot;acharné&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;b√™te&quot;, &quot;bête&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;blas\x8e&quot;, &quot;blasé&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;bont√©&quot;, &quot;bonté&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;bo√∂pis&quot;, &quot;boöpis&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;born√©&quot;, &quot;borné&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;d√©gag√©&quot;, &quot;dégagé&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;d√©pays√©&quot;, &quot;dépaysé&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;d√©sorient√©&quot;, &quot;désorienté&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;distingu√©&quot;, &quot;distingué&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;d√ºreresque&quot;, &quot;düreresque&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;√©clat&quot;, &quot;éclat&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;effar√©&quot;, &quot;effaré&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;√©l√©gante&quot;, &quot;élégante&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;√©lite&quot;, &quot;élite&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;ent√™t√©&quot;, &quot;entêté&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;espi√®gle&quot;, &quot;espiègle&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;fa√´rie&quot;, &quot;faërie&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;fain√©ant&quot;, &quot;fainéant&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;FALSE&quot;, &quot;false&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;outr√©&quot;, &quot;outré&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;pr√©cieuse&quot;, &quot;précieuse&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;r√©chauff√©&quot;, &quot;réchauffé&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;rou√©&quot;, &quot;roué&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;TRUE&quot;, &quot;true&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;unco√∂rdinated&quot;, &quot;uncoördinated&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;zo√∂id&quot;, &quot;zoöid&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;zo√∂philous&quot;, &quot;zoöphilous&quot;, ngrams_all_avgfreq$TDA)</code></pre>
</div>
<div id="analyses" class="section level2">
<h2>Analyses</h2>
<div id="calculate-overall-means-and-compare-differences-using-t-tests-1" class="section level3">
<h3>1. Calculate overall means and compare differences using t-tests</h3>
<p>Calculate the overall means for each of the TDA + noun vectors. In other words, find the means for all the TDA + person ngrams, TDA + man ngrams, woman, girl, and boy. Then compare the means with t-tests. This is repeated using the holm corrections.</p>
<pre class="r"><code># drop the column of TDA labels
ngrams_avgfreq &lt;- subset(ngrams_all_avgfreq, select = -c(TDA))
means_vector &lt;- c()
for (j in 1:ncol(ngrams_avgfreq))
{
  means_vector[j] &lt;- mean( unname(unlist(ngrams_avgfreq[,j])), na.rm = TRUE)
}

names(means_vector) &lt;- NOUNS_LIST
means_vector</code></pre>
<pre><code>##            person             woman               man              girl 
## 0.000000009147355 0.000000009897305 0.000000018108562 0.000000008428365 
##               boy 
## 0.000000005711492</code></pre>
<pre class="r"><code>ngrams_all_longForm &lt;- ngrams_avgfreq %&gt;%
  gather(form, value, freq_avg_person:freq_avg_boy)

ngrams_uncorrected_ttests &lt;- pairwise.t.test(x = ngrams_all_longForm$value, 
                                             g = ngrams_all_longForm$form, 
                                             p.adjust.method = &quot;none&quot;)
ngrams_holm_ttests &lt;- pairwise.t.test(x = ngrams_all_longForm$value, 
                                             g = ngrams_all_longForm$form, 
                                             p.adjust.method = &quot;holm&quot;)</code></pre>
<p>Next, show the p-values for the uncorrected t-tests of means, then the holm-corrected p-values. None of the t-tests are significant when using corrections of either type. If using uncorrected means (not recommended), the largest differences in means are for boy-man, person-man, girl-man, woman-man (in that order).</p>
<pre class="r"><code>round(ngrams_uncorrected_ttests$p.value, 3)</code></pre>
<pre><code>##                 freq_avg_boy freq_avg_girl freq_avg_man freq_avg_person
## freq_avg_girl          0.607            NA           NA              NA
## freq_avg_man           0.007         0.034           NA              NA
## freq_avg_person        0.485         0.883        0.031              NA
## freq_avg_woman         0.392         0.762        0.046           0.866</code></pre>
<pre class="r"><code>round(ngrams_holm_ttests$p.value, 3)</code></pre>
<pre><code>##                 freq_avg_boy freq_avg_girl freq_avg_man freq_avg_person
## freq_avg_girl          1.000            NA           NA              NA
## freq_avg_man           0.072         0.279           NA              NA
## freq_avg_person        1.000         1.000        0.279              NA
## freq_avg_woman         1.000         1.000        0.324               1</code></pre>
</div>
<div id="calculate-z-scores-1" class="section level3">
<h3>2. Calculate z-scores</h3>
<p>Now that we have compared the raw means in the prior step, we create a table of the zscores of the 10-year averages for each TDA + noun ngram. These are the data posted on Dataverse, as shown below.</p>
<pre class="r"><code>ngrams_all_zscores &lt;- tibble(
  TDA = ngrams_person$term,
  coded = ngrams_person$coded,
  person_zscore = ngrams_person$zscore,
  woman_zscore = ngrams_woman$zscore,
  man_zscore = ngrams_man$zscore,
  girl_zscore = ngrams_girl$zscore,
  boy_zscore = ngrams_boy$zscore
)
ngrams_all_zscores &lt;- subset(ngrams_all_zscores, TDA != &quot;self-harming&quot;)</code></pre>
<pre class="r"><code>write_csv(ngrams_all_zscores, 
          file = here(&quot;data/ngrams/ngrams_all_zscores.csv&quot;))</code></pre>
<p>This csv file (above) has been posted publicly on Dataverse (see doi). All subsequent analyses of the ngrams data are based on this file, including the database of ngram estimates (see <a href="https://pie-lab.github.io/tdafrequency/ngrams-frequency.html">here</a>).</p>
<p><em>ADD DOI LINK TO THE SENTENCE ABOVE</em></p>
<p>The following code clears the environment and loads the data directly from Dataverse.</p>
<p><em>CHANGE THIS TO PULL THE ZSCORES FILE FROM DATAVERSE.</em></p>
<pre class="r"><code>rm(list=ls())
ngrams_all_zscores &lt;- read_csv(here(&quot;data/ngrams/ngrams_all_zscores.csv&quot;))</code></pre>
<pre class="r"><code>library(dataverse)
library(data.table)

Sys.setenv(&quot;DATAVERSE_SERVER&quot; = &quot;dataverse.harvard.edu&quot;)
writeBin(get_file(&quot;TDA_data_scored.tab&quot;, &quot;doi:10.7910/DVN/5T80PF&quot;), &quot;TDA_data_scored.tab&quot;)
TDA_data_scored.tab &lt;- fread(&quot;TDA_data_scored.tab&quot;, na.strings=getOption(&quot;&lt;NA&gt;&quot;,&quot;NA&quot;))
data &lt;- as.data.frame(TDA_data_scored.tab)
rm(TDA_data_scored.tab)</code></pre>
</div>
<div id="correlations-between-the-5-tda-noun-vectors-1" class="section level3">
<h3>3. Correlations between the 5 TDA + noun vectors</h3>
<p>Note that there is a more nicely formatted table in the manuscript referenced at the top of this page.</p>
<pre class="r"><code># drop the column of TDA labels
ngrams_zscores &lt;- subset(ngrams_all_zscores, select = -c(TDA, coded))
cor_ngrams &lt;- corr.test(ngrams_zscores,
                        use = &quot;pairwise&quot;, 
                        method = &quot;pearson&quot;, 
                        alpha = 0.05,
                        ci = TRUE)

cor_ngrams_ci &lt;- tibble(
  noun1 = c(&quot;person&quot;, &quot;person&quot;, &quot;person&quot;, &quot;person&quot;, &quot;woman&quot;, 
             &quot;woman&quot;, &quot;woman&quot;, &quot;man&quot;, &quot;man&quot;, &quot;girl&quot;),
  noun2 = c(&quot;woman&quot;, &quot;man&quot;, &quot;girl&quot;, &quot;boy&quot;, &quot;man&quot;, 
             &quot;girl&quot;, &quot;boy&quot;, &quot;girl&quot;, &quot;boy&quot;, &quot;boy&quot;),
  lower_bound = cor_ngrams$ci.adj$lower,
  r = cor_ngrams$ci$r,
  upper_bound = cor_ngrams$ci.adj$upper,
  p_value = cor_ngrams$ci2$p
)</code></pre>
<p>The table below shows the correlations between noun pairs with the lower and upper bounds of the 95% confidence intervals.</p>
<pre><code>##     noun1 noun2 lower_bound     r upper_bound p_value
## 1  person woman       0.337 0.371       0.404       0
## 2  person   man       0.307 0.339       0.370       0
## 3  person  girl       0.164 0.198       0.232       0
## 4  person   boy       0.174 0.214       0.253       0
## 5   woman   man       0.958 0.961       0.964       0
## 6   woman  girl       0.418 0.454       0.489       0
## 7   woman   boy       0.523 0.557       0.589       0
## 8     man  girl       0.433 0.469       0.504       0
## 9     man   boy       0.580 0.610       0.639       0
## 10   girl   boy       0.951 0.956       0.960       0</code></pre>
</div>
<div id="calculate-the-ngrams-frequency-index" class="section level3">
<h3>4. Calculate the Ngrams frequency index</h3>
<p>Here, we find the frequencies index by finding the average of the z-scores across all 5 TDA + noun pairs for each TDA <em>after</em> removing the max z-score for each TDA. In other words, find the average among all but the largest z-score for each TDA. This approach is used to reduce the skew introduced in a few cases where the pairing of a specific TDA + noun is part of a song, book, famous individual, etc.</p>
<p>Output from the following section of code is used to populate the ngram column of the <a href="https://pie-lab.github.io/tdafrequency/ngrams-frequency.html">database of frequencies</a> provided on this website.</p>
<pre class="r"><code>bucket &lt;- c()
for (j in 1:nrow(ngrams_zscores)) 
{
  vector_i &lt;- c()
  vector_i &lt;- unname(unlist(ngrams_zscores[j,]))
  vector_i &lt;- vector_i[vector_i != max(vector_i, na.rm = TRUE)] #remove max zsc
  freq_val &lt;- mean(vector_i, na.rm = TRUE)
  bucket[j] &lt;- freq_val
}

ngrams_freq_index &lt;- ngrams_zscores %&gt;%
  mutate(
    freq_index = bucket
  ) 

ngrams_freq_index &lt;- ngrams_freq_index %&gt;%
  mutate(
    TDA = ngrams_all_zscores$TDA,
    freq_index = if_else(condition = is.nan(freq_index), 
                         true = as.double(NA), 
                         false = freq_index),
  ) %&gt;%
    select(TDA, everything())</code></pre>
</div>
</div>
</div>
<div id="correlation-between-search-engine-and-ngram-estimates" class="section level1">
<h1>Correlation between search engine and ngram estimates</h1>
<p>This is done by creating a large data frame with all the search engine and ngram estimates for each descriptor. Note that (1) this analysis overlaps with the correlational analyses previously reported within type, and (2) there is a more nicely formatted table in the manuscript referenced at the top of this page. In the manuscript, we report the holm-adjusted confidence intervals around the correlations.</p>
<pre class="r"><code>ngrams &lt;- as.data.frame(ngrams_freq_index)[,c(&quot;person_zscore&quot;, &quot;woman_zscore&quot;, &quot;man_zscore&quot;, &quot;girl_zscore&quot;, &quot;boy_zscore&quot;, &quot;freq_index&quot;)]
rownames(ngrams) &lt;- as.data.frame(ngrams_freq_index)[,&quot;TDA&quot;]
colnames(ngrams) &lt;- c(&quot;person_ngrams&quot;, &quot;woman_ngrams&quot;, &quot;man_ngrams&quot;, &quot;girl_ngrams&quot;, &quot;boy_ngrams&quot;, &quot;index_ngrams&quot;)

serps_freq_index &lt;- read_csv(here(&quot;data/serps/serps_freq_index.csv&quot;))
serps &lt;- as.data.frame(serps_freq_index)[,c(&quot;person_zscore&quot;, &quot;woman_zscore&quot;, &quot;man_zscore&quot;, &quot;girl_zscore&quot;, &quot;boy_zscore&quot;, &quot;freq_index&quot;)]
rownames(serps) &lt;- as.data.frame(serps_freq_index)[,&quot;TDA&quot;]
colnames(serps) &lt;- c(&quot;person_serps&quot;, &quot;woman_serps&quot;, &quot;man_serps&quot;, &quot;girl_serps&quot;, &quot;boy_serps&quot;, &quot;index_serps&quot;)

all &lt;- data.frame(serps, ngrams)
all_cor &lt;- corr.test(all, use=&quot;pairwise&quot;, method = &quot;pearson&quot;, alpha = .05, ci=TRUE)
round(all_cor$r, 3)</code></pre>
<pre><code>##               person_serps woman_serps man_serps girl_serps boy_serps index_serps
## person_serps         1.000       0.063     0.037      0.037     0.032       0.068
## woman_serps          0.063       1.000     0.708      0.645     0.508       0.924
## man_serps            0.037       0.708     1.000      0.532     0.380       0.764
## girl_serps           0.037       0.645     0.532      1.000     0.583       0.743
## boy_serps            0.032       0.508     0.380      0.583     1.000       0.696
## index_serps          0.068       0.924     0.764      0.743     0.696       1.000
## person_ngrams        0.163       0.382     0.291      0.233     0.265       0.432
## woman_ngrams         0.052       0.909     0.842      0.559     0.471       0.888
## man_ngrams           0.042       0.813     0.902      0.524     0.472       0.844
## girl_ngrams          0.023       0.411     0.395      0.488     0.829       0.565
## boy_ngrams           0.025       0.453     0.561      0.519     0.812       0.617
## index_ngrams         0.054       0.819     0.808      0.603     0.704       0.901
##               person_ngrams woman_ngrams man_ngrams girl_ngrams boy_ngrams index_ngrams
## person_serps          0.163        0.052      0.042       0.023      0.025        0.054
## woman_serps           0.382        0.909      0.813       0.411      0.453        0.819
## man_serps             0.291        0.842      0.902       0.395      0.561        0.808
## girl_serps            0.233        0.559      0.524       0.488      0.519        0.603
## boy_serps             0.265        0.471      0.472       0.829      0.812        0.704
## index_serps           0.432        0.888      0.844       0.565      0.617        0.901
## person_ngrams         1.000        0.371      0.339       0.198      0.214        0.408
## woman_ngrams          0.371        1.000      0.961       0.454      0.557        0.920
## man_ngrams            0.339        0.961      1.000       0.469      0.610        0.930
## girl_ngrams           0.198        0.454      0.469       1.000      0.956        0.728
## boy_ngrams            0.214        0.557      0.610       0.956      1.000        0.805
## index_ngrams          0.408        0.920      0.930       0.728      0.805        1.000</code></pre>
</div>
<div id="comparison-with-roivainen-2013" class="section level1">
<h1>Comparison with Roivainen (2013)</h1>
<p>As pre-registered, we evaluated the correlation between the frequency estimates presented here and the estimates reported in Roivainen (2013). This was done using z-scored versions of the raw counts provided by Roivainen (personal correspondence).</p>
<pre class="r"><code>rm(list=ls())
roivainen &lt;- read_csv(here(&quot;data/other/roivainen_comparison.csv&quot;))

serps_freq_index &lt;- read_csv(here(&quot;data/serps/serps_freq_index.csv&quot;))
serps_freq &lt;- as.data.frame(serps_freq_index[,c(&quot;person_zscore&quot;, &quot;freq_index&quot;)])
rownames(serps_freq) &lt;- serps_freq_index$TDA
roivainen_435_serps &lt;- serps_freq[as.data.frame(roivainen)[,1],]
colnames(roivainen_435_serps) &lt;- c(&quot;person_serps&quot;, &quot;index_serps&quot;)

ngrams_freq_index &lt;- read_csv(here(&quot;data/ngrams/ngrams_freq_index.csv&quot;))
ngrams_freq &lt;- as.data.frame(ngrams_freq_index[,c(&quot;person_zscore&quot;, &quot;freq_index&quot;)])
rownames(ngrams_freq) &lt;- ngrams_freq_index$TDA
roivainen_435_ngrams &lt;- ngrams_freq[as.data.frame(roivainen)[,1],]
colnames(roivainen_435_ngrams) &lt;- c(&quot;person_ngrams&quot;, &quot;index_ngrams&quot;)

roivainen &lt;- data.frame(roivainen[,&quot;Rserps2012z&quot;], roivainen_435_serps, roivainen[,&quot;Rngrams2000z&quot;], roivainen_435_ngrams)

roivainenCor &lt;- corr.test(roivainen, 
                                    use = &quot;pairwise&quot;,
                                    method = &quot;pearson&quot;,
                                    alpha = .05,
                                    ci = TRUE)

roivainenCorci &lt;- tibble(
  group1 = c(&quot;serps_person2012z&quot;, &quot;serps_person2012z&quot;, &quot;serps_person2012z&quot;, &quot;serps_person2012z&quot;, &quot;serps_person2012z&quot;, &quot;serps_person2022z&quot;, &quot;serps_person2022z&quot;, &quot;serps_person2022z&quot;, &quot;serps_person2022z&quot;, &quot;serps_freq_index2022&quot;, &quot;serps_freq_index2022&quot;, &quot;serps_freq_index2022&quot;, &quot;ngrams_person2000z&quot;, &quot;ngrams_person2000z&quot;, &quot;ngrams_person2019z&quot;), 
  group2 = c(&quot;serps_person2022z&quot;, &quot;serps_freq_index2022&quot;, &quot;ngrams_person2000z&quot;, &quot;ngrams_person2019z&quot;, &quot;ngrams_freq_index2019&quot;, &quot;serps_freq_index2022&quot;, &quot;ngrams_person2000z&quot;, &quot;ngrams_person2019z&quot;, &quot;ngrams_freq_index2019&quot;, &quot;ngrams_person2000z&quot;, &quot;ngrams_person2019z&quot;, &quot;ngrams_freq_index2019&quot;, &quot;ngrams_person2019z&quot;, &quot;ngrams_freq_index2019&quot;, &quot;ngrams_freq_index2019&quot;),
  lower_bound = roivainenCor$ci.adj$lower,
  r = roivainenCor$ci$r,
  upper_bound = roivainenCor$ci.adj$upper,
  p_value = roivainenCor$ci2$p
)
roivainenCorci[c(1,2,13,14),] # we are only interested in a few</code></pre>
<pre><code>## # A tibble: 4 × 6
##   group1             group2              lower_bound     r upper_bound   p_value
##   &lt;chr&gt;              &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;
## 1 serps_person2012z  serps_person2022z        0.815  0.857       0.890 8.97e-126
## 2 serps_person2012z  serps_freq_index20…      0.0964 0.214       0.326 7.27e-  6
## 3 ngrams_person2000z ngrams_person2019z       0.806  0.887       0.936 1.02e- 35
## 4 ngrams_person2000z ngrams_freq_index2…      0.0998 0.349       0.557 3.06e-  4</code></pre>
<pre><code>##          dev_woman     dev_man    dev_girl     dev_boy
## little -11.9350637 -9.01966790 38.97418217 32.70550553
## good    -3.7121148  1.79613290 -0.43812725  2.35410914
## bad     -1.7699863 -0.80287540 -0.78752600  3.64414535
## big     -1.6149272  3.58206786 -0.12453197  3.81520112
## nice    -0.6630211 -0.08812047  0.68434703  0.06679451
## best    -0.5792884  1.47331559 -0.41187970 -0.48214750
## blind   -0.4136589  1.68933880 -0.59260139 -0.56574582
## rich    -0.3464752  3.13542810 -0.17746971 -0.24539453
## last    -0.3280798  1.28240861 -0.48099022 -0.47333863
## dead    -0.2830143  4.30680793 -1.26596570 -1.56495085
## gay     -0.2666163  0.92246990 -0.30485943 -0.12838696
## dear    -0.2105023 -0.18037618  0.82651243  3.24736933
## great   -0.1963551  2.87390418 -0.40283056 -0.57531911
## common  -0.1903876  1.30588138 -0.25394200 -0.27048348
## lost    -0.1898209 -0.13030346  0.02801681  0.45634063</code></pre>
<pre><code>##              dev_woman      dev_man     dev_girl      dev_boy
## pretty       0.8970556 -1.233722744  3.160693769  1.640841192
## naked        0.9492511  0.262810539  0.065082470 -0.087345551
## battered     0.9585732  0.013479239  0.007689448 -0.002444374
## samaritan    1.2444953  0.006800356  0.003931149 -0.010731505
## single       1.3283225  0.267637852 -0.575804172 -1.020156193
## attractive   1.7818308  0.062185992  0.060249067 -0.275465179
## white        2.1094618  6.812456487 -2.780034321 -1.568776482
## middle-aged  2.4185022  1.239121562 -0.441248171 -0.447643731
## elderly      2.7416938  0.592009351 -1.357161468 -1.366405415
## black        3.8045677  3.866179008 -3.164076600 -2.117208721
## first        4.1881072  0.365662758 -2.286975305 -2.266794675
## pregnant     6.2984399 -0.098180321  0.147723003 -0.129092244
## beautiful    7.9748086 -1.251445856  1.988484988 -0.447062365
## old         19.7044159 35.331937952 -7.942652603  4.692086017
## young       26.0800198 28.046594423 -6.720707914 -8.141387499</code></pre>
<pre><code>##                 dev_woman    dev_man    dev_girl      dev_boy
## little      -11.935063661 -9.0196679 38.97418217 32.705505531
## beautiful     7.974808646 -1.2514459  1.98848499 -0.447062365
## pretty        0.897055575 -1.2337227  3.16069377  1.640841192
## bad          -1.769986344 -0.8028754 -0.78752600  3.644145348
## lovely        0.592544938 -0.3432763  0.46068138 -0.180368122
## sweet        -0.165012606 -0.2843777  1.07144109  0.589008146
## jewish        0.648994219 -0.2579943 -0.01956209  0.374262118
## human         0.183788154 -0.2149786  0.01252380  0.018666604
## dear         -0.210502338 -0.1803762  0.82651243  3.247369334
## independent   0.629018496 -0.1694869 -0.20907415 -0.250457491
## english       0.185113418 -0.1653859  0.25269343  0.048505901
## stupid       -0.062448198 -0.1316915  0.17797255  0.085109279
## lost         -0.189820945 -0.1303035  0.02801681  0.456340635
## tiny          0.305167939 -0.1255398  0.13756795 -0.007627161
## silly        -0.007037702 -0.1184337  0.45025673  0.356795087</code></pre>
<pre><code>##            dev_woman   dev_man   dev_girl    dev_boy
## fat       0.03708667  1.443002 -0.2093927  0.4626991
## best     -0.57928839  1.473316 -0.4118797 -0.4821475
## blind    -0.41365894  1.689339 -0.5926014 -0.5657458
## handsome  0.10822707  1.711912 -0.3218953  0.5624347
## good     -3.71211479  1.796133 -0.4381272  2.3541091
## wise      0.29623097  1.858562 -1.0672677 -1.0875249
## tall      0.62381442  2.374359 -0.2530287  0.1005203
## great    -0.19635511  2.873904 -0.4028306 -0.5753191
## rich     -0.34647521  3.135428 -0.1774697 -0.2453945
## big      -1.61492718  3.582068 -0.1245320  3.8152011
## black     3.80456775  3.866179 -3.1640766 -2.1172087
## dead     -0.28301428  4.306808 -1.2659657 -1.5649508
## white     2.10946178  6.812456 -2.7800343 -1.5687765
## young    26.08001985 28.046594 -6.7207079 -8.1413875
## old      19.70441588 35.331938 -7.9426526  4.6920860</code></pre>
<pre><code>##           dev_woman    dev_man   dev_girl    dev_boy
## old     19.70441588 35.3319380 -7.9426526  4.6920860
## young   26.08001985 28.0465944 -6.7207079 -8.1413875
## black    3.80456775  3.8661790 -3.1640766 -2.1172087
## white    2.10946178  6.8124565 -2.7800343 -1.5687765
## first    4.18810722  0.3656628 -2.2869753 -2.2667947
## elderly  2.74169381  0.5920094 -1.3571615 -1.3664054
## dead    -0.28301428  4.3068079 -1.2659657 -1.5649508
## wise     0.29623097  1.8585616 -1.0672677 -1.0875249
## bad     -1.76998634 -0.8028754 -0.7875260  3.6441453
## free     0.48040133  1.0720139 -0.6799246 -0.7087603
## strong   0.74836475  0.8226984 -0.6636507 -0.4805386
## blind   -0.41365894  1.6893388 -0.5926014 -0.5657458
## single   1.32832251  0.2676379 -0.5758042 -1.0201562
## real     0.18826002  0.6254890 -0.4983613 -0.3153877
## second   0.06954701  0.7642398 -0.4838151 -0.3499717</code></pre>
<pre><code>##               dev_woman      dev_man   dev_girl     dev_boy
## darling    -0.090243801 -0.066772847  0.3222917  0.36138763
## dancing     0.032266066  0.021623052  0.3251283  0.02916216
## funny      -0.074175276  0.080269440  0.3259407  0.02655978
## mean       -0.075469936  0.007422568  0.3401588 -0.08554929
## blond       0.745812810  0.006309323  0.3568994  0.27848424
## smart      -0.022474412 -0.099352079  0.4175527  0.07384993
## silly      -0.007037702 -0.118433705  0.4502567  0.35679509
## lovely      0.592544938 -0.343276253  0.4606814 -0.18036812
## poor       -0.137427082  0.845074148  0.4744821  0.18952656
## nice       -0.663021068 -0.088120465  0.6843470  0.06679451
## dear       -0.210502338 -0.180376184  0.8265124  3.24736933
## sweet      -0.165012606 -0.284377657  1.0714411  0.58900815
## beautiful   7.974808646 -1.251445856  1.9884850 -0.44706236
## pretty      0.897055575 -1.233722744  3.1606938  1.64084119
## little    -11.935063661 -9.019667902 38.9741822 32.70550553</code></pre>
<pre><code>##          dev_woman     dev_man   dev_girl    dev_boy
## young   26.0800198 28.04659442 -6.7207079 -8.1413875
## first    4.1881072  0.36566276 -2.2869753 -2.2667947
## black    3.8045677  3.86617901 -3.1640766 -2.1172087
## white    2.1094618  6.81245649 -2.7800343 -1.5687765
## dead    -0.2830143  4.30680793 -1.2659657 -1.5649508
## elderly  2.7416938  0.59200935 -1.3571615 -1.3664054
## wise     0.2962310  1.85856155 -1.0672677 -1.0875249
## single   1.3283225  0.26763785 -0.5758042 -1.0201562
## new      0.6066782  0.05802658  0.1871828 -0.8518875
## free     0.4804013  1.07201386 -0.6799246 -0.7087603
## great   -0.1963551  2.87390418 -0.4028306 -0.5753191
## blind   -0.4136589  1.68933880 -0.5926014 -0.5657458
## right    0.1428781  0.57560442 -0.2055202 -0.5129623
## best    -0.5792884  1.47331559 -0.4118797 -0.4821475
## strong   0.7483647  0.82269838 -0.6636507 -0.4805386</code></pre>
<pre><code>##              dev_woman     dev_man    dev_girl    dev_boy
## local      0.076161033 -0.08574363  0.09633485  0.5522838
## handsome   0.108227073  1.71191179 -0.32189527  0.5624347
## sweet     -0.165012606 -0.28437766  1.07144109  0.5890081
## naughty   -0.080326058 -0.05776414  0.27484483  0.7941366
## game       0.006237901  0.01945337  0.03029676  0.9257808
## stable    -0.037418168 -0.01150536 -0.02062396  1.1041386
## pretty     0.897055575 -1.23372274  3.16069377  1.6408412
## golden    -0.052664915 -0.03168614  0.23521555  1.8593640
## good      -3.712114792  1.79613290 -0.43812725  2.3541091
## dear      -0.210502338 -0.18037618  0.82651243  3.2473693
## bad       -1.769986344 -0.80287540 -0.78752600  3.6441453
## big       -1.614927184  3.58206786 -0.12453197  3.8152011
## old       19.704415884 35.33193795 -7.94265260  4.6920860
## small     -0.060457586  0.08252710  0.21845662  6.3020947
## little   -11.935063661 -9.01966790 38.97418217 32.7055055</code></pre>
<pre><code>##           dev_woman    dev_man   dev_girl    dev_boy
## little   -9.3752519 -3.9755091 24.3228557 77.7450367
## good     -6.0584881  6.8983327  2.2176487 10.8797725
## bad      -3.0780312 -1.2862168  7.3256728 33.4467225
## big      -2.3016247  1.8209020  4.9070196 21.5841015
## gay      -2.1874440  6.7078279 -2.1447662 18.1056358
## best     -2.0320975  2.8419285  1.1376076  2.4105418
## new      -1.7490473  0.1493156  9.0067186  4.4158821
## lucky    -1.7480824  3.4134816  0.1555239  4.2712482
## small    -1.4642363 -0.2602656  3.5149869  9.5507866
## horny    -1.3696037 -0.9124428 10.1059623  6.0819063
## it       -0.8210216  1.3001772  2.3231965  1.4248533
## crazy    -0.7771489 -0.7820441  2.2192097  1.9098866
## naughty  -0.7236985 -0.8524494  2.9518846  6.0692377
## cool     -0.6838913  0.5201010  3.3188439  1.1080390
## innocent -0.6628324  0.8773653  1.5467795  0.5939014</code></pre>
<pre><code>##            dev_woman    dev_man   dev_girl     dev_boy
## attractive  3.674886  0.5580097  0.5161665  -0.4595009
## elderly     4.123081  2.3182462 -0.9203370  -1.1355041
## strong      4.331303  2.3111725 -0.2704791  -1.1972686
## naked       5.137605  3.3384500  5.0026071  -3.9557657
## happy       8.167490 -2.2511839  1.7308982   2.0152827
## addicted    8.299391  0.9936971 -0.3942642  -0.3394183
## sexy        9.922869 -3.2697776 21.4089811  -0.1876102
## black      11.168507 16.4632609 18.5819777  -7.6133000
## first      11.843555 -2.6480178 -4.8603739  -4.3351633
## pretty     13.879861  0.4478997 -0.2067581  -0.2111515
## pregnant   16.091676 -0.4065818  1.3148434  -0.3501268
## beautiful  21.182181 -6.9978992 29.1039477  -4.6873390
## old        21.908146 83.2423243 13.7161746 -18.2173130
## mature     25.100778  2.7914172  1.7448243  -2.4124382
## young      61.869850 13.6443807  6.2784629  22.4878604</code></pre>
<pre><code>##            dev_woman    dev_man   dev_girl    dev_boy
## beautiful 21.1821812 -6.9978992 29.1039477 -4.6873390
## little    -9.3752519 -3.9755091 24.3228557 77.7450367
## sexy       9.9228687 -3.2697776 21.4089811 -0.1876102
## first     11.8435550 -2.6480178 -4.8603739 -4.3351633
## hot        2.1741508 -2.2905879 72.1897920  4.8281562
## happy      8.1674900 -2.2511839  1.7308982  2.0152827
## bad       -3.0780312 -1.2862168  7.3256728 33.4467225
## horny     -1.3696037 -0.9124428 10.1059623  6.0819063
## blond      1.7994756 -0.8749871  1.6206653  0.5230289
## cat        1.1329227 -0.8537973  5.4022496  0.4843206
## naughty   -0.7236985 -0.8524494  2.9518846  6.0692377
## cute       2.4606340 -0.8496717 30.6582113 -0.8579026
## female     0.8435869 -0.7844271  0.5874983  0.6789337
## crazy     -0.7771489 -0.7820441  2.2192097  1.9098866
## pussy      0.3237625 -0.6822292  4.4526659  1.0860605</code></pre>
<pre><code>##                dev_woman   dev_man     dev_girl      dev_boy
## bearded     -0.003916872  4.045093 -0.009022917   0.07265645
## rich        -0.475695394  4.357291  0.957568061   0.51334729
## great        0.358891244  4.360985 -0.783786220   0.14314163
## interesting -0.034180349  4.849306  0.113992902  -0.08101446
## burning     -0.032977849  5.299761 -0.004729567   0.10293784
## last        -0.141355127  6.517185 -0.361286568  -0.05708976
## dead         0.292772043  6.556776  0.408776720  -0.49753004
## gay         -2.187443979  6.707828 -2.144766206  18.10563584
## good        -6.058488146  6.898333  2.217648738  10.87977246
## punch       -0.012139001  8.943691  0.013748421   0.02940357
## dog         -0.474337517  9.110857  0.397502989   0.60392626
## young       61.869850349 13.644381  6.278462897  22.48786039
## black       11.168506644 16.463261 18.581977734  -7.61329996
## iron         0.076996681 34.013940 -0.017418980   0.02296256
## old         21.908146007 83.242324 13.716174628 -18.21731300</code></pre>
<pre><code>##                  dev_woman    dev_man   dev_girl    dev_boy
## first          11.84355503 -2.6480178 -4.8603739 -4.3351633
## gay            -2.18744398  6.7078279 -2.1447662 18.1056358
## elderly         4.12308087  2.3182462 -0.9203370 -1.1355041
## single          1.74903874  0.6798855 -0.8486135 -1.5803108
## great           0.35889124  4.3609850 -0.7837862  0.1431416
## better         -0.62137368  1.8756180 -0.7517521 -0.4655625
## middle-aged     2.74134395  1.9977696 -0.6800373 -0.6799583
## male            0.04922817  0.8351180 -0.6695296  1.7314045
## right          -0.35057236  1.5209727 -0.5716959 -0.5987044
## sick           -0.23104503  0.9647828 -0.5095199  0.4939764
## casual          0.19052252  0.5385002 -0.4661786  0.9230598
## average         0.81632982  0.1912931 -0.4518542 -0.5270144
## free            0.29035316  1.7768448 -0.4486746  2.2747131
## depersonalized  1.91589416  1.2903421 -0.4416910 -0.4461169
## second          0.27216967  0.3998719 -0.4201554 -0.2518861</code></pre>
<pre><code>##             dev_woman     dev_man  dev_girl     dev_boy
## white      1.78375935  2.84768141  7.075760   5.6286478
## sweet     -0.37902232 -0.68187311  7.091967   2.9245332
## bad       -3.07803124 -1.28621683  7.325673  33.4467225
## german     0.23654584 -0.09746006  7.790949   0.4008287
## skinny     0.13594899 -0.54465404  8.768149   1.6456462
## new       -1.74904726  0.14931564  9.006719   4.4158821
## horny     -1.36960371 -0.91244282 10.105962   6.0819063
## cam       -0.00961754 -0.26075582 11.003619   0.5986347
## old       21.90814601 83.24232434 13.716175 -18.2173130
## black     11.16850664 16.46326087 18.581978  -7.6133000
## sexy       9.92286872 -3.26977765 21.408981  -0.1876102
## little    -9.37525191 -3.97550911 24.322856  77.7450367
## beautiful 21.18218121 -6.99789922 29.103948  -4.6873390
## cute       2.46063400 -0.84967175 30.658211  -0.8579026
## hot        2.17415085 -2.29058791 72.189792   4.8281562</code></pre>
<pre><code>##            dev_woman     dev_man   dev_girl     dev_boy
## old       21.9081460 83.24232434 13.7161746 -18.2173130
## black     11.1685066 16.46326087 18.5819777  -7.6133000
## beautiful 21.1821812 -6.99789922 29.1039477  -4.6873390
## first     11.8435550 -2.64801779 -4.8603739  -4.3351633
## naked      5.1376053  3.33845002  5.0026071  -3.9557657
## mature    25.1007776  2.79141717  1.7448243  -2.4124382
## nice       0.7924295  0.92054856  4.3338311  -1.6390074
## single     1.7490387  0.67988553 -0.8486135  -1.5803108
## real       1.5091061  3.54610352  0.6321148  -1.5439057
## strong     4.3313032  2.31117248 -0.2704791  -1.1972686
## elderly    4.1230809  2.31824617 -0.9203370  -1.1355041
## lovely     1.3650663  0.03745268  3.4862966  -0.9005215
## natural    1.0378148 -0.22965650  1.0128657  -0.8613623
## cute       2.4606340 -0.84967175 30.6582113  -0.8579026
## depressed  1.7502309  0.98105281 -0.3035603  -0.7242267</code></pre>
<pre><code>##            dev_woman     dev_man    dev_girl   dev_boy
## beast    -0.05675579  0.14000242 -0.01941671  6.244109
## lady      0.22954219  0.10709682  0.11404872  6.250749
## sissy     0.26417630 -0.27272687  0.38038085  6.402525
## straight -0.53647525  1.38569992  0.14044398  6.808891
## handsome  0.03515349 -0.24435695  0.34656325  8.323608
## small    -1.46423631 -0.26026555  3.51498686  9.550787
## fat       1.93236151  1.00032642  1.22960070  9.635718
## good     -6.05848815  6.89833271  2.21764874 10.879772
## out      -0.38990619  1.03529784 -0.06523989 11.138978
## gay      -2.18744398  6.70782789 -2.14476621 18.105636
## game     -0.05773113  0.00786943  0.29273672 19.808874
## big      -2.30162474  1.82090205  4.90701956 21.584102
## young    61.86985035 13.64438075  6.27846290 22.487860
## bad      -3.07803124 -1.28621683  7.32567284 33.446722
## little   -9.37525191 -3.97550911 24.32285572 77.745037</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
