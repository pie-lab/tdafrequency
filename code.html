<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Analytic Code</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">TDA</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="serps-frequency.html">Estimates based on Search Engine Results</a>
</li>
<li>
  <a href="ngrams-frequency.html">Estimates based on Ngram Results</a>
</li>
<li>
  <a href="code.html">Code</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://psyarxiv.com">
    <span class="fa fa-file"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/pie-lab/tdafrequency">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Analytic Code</h1>
<h4 class="date">Last updated 2022-04-18</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#prepare-the-environment">Prepare the environment</a></li>
<li><a href="#derive-the-search-engine-frequency-estimates">Derive the search engine frequency estimates</a>
<ul>
<li><a href="#data-loading-and-preparation">Data loading and preparation</a>
<ul>
<li><a href="#calculate-overall-means-and-compare-differences-using-t-tests">1. Calculate overall means and compare differences using t-tests</a></li>
<li><a href="#calculate-z-scores">2. Calculate z-scores</a></li>
<li><a href="#correlations-between-the-5-tda-noun-vectors">3. Correlations between the 5 TDA + noun vectors</a></li>
<li><a href="#calculate-the-search-engine-frequency-index">4. Calculate the search engine frequency index</a></li>
</ul></li>
</ul></li>
<li><a href="#derive-the-ngram-frequency-estimates">Derive the ngram frequency estimates</a>
<ul>
<li><a href="#data-loading-and-preparation-1">Data loading and preparation</a></li>
<li><a href="#analyses">Analyses</a>
<ul>
<li><a href="#calculate-overall-means-and-compare-differences-using-t-tests-1">1. Calculate overall means and compare differences using t-tests</a></li>
<li><a href="#calculate-z-scores-1">2. Calculate z-scores</a></li>
<li><a href="#correlations-between-the-5-tda-noun-vectors-1">3. Correlations between the 5 TDA + noun vectors</a></li>
<li><a href="#calculate-the-ngrams-frequency-index">4. Calculate the Ngrams frequency index</a></li>
</ul></li>
</ul></li>
<li><a href="#correlation-between-search-engine-and-ngram-estimates">Correlation between search engine and ngram estimates</a></li>
<li><a href="#comparison-with-roivainen-2013">Comparison with Roivainen (2013)</a></li>
</ul>
</div>

<div id="prepare-the-environment" class="section level1">
<h1>Prepare the environment</h1>
<pre class="r"><code>library(here) # for engaging with working environment
library(rio) # for importing excel files
library(psych) # for scoring multiple choice items
library(R.utils) # just for the insert() function
library(tidyverse) # for data cleaning and manipulation
library(matrixStats)
library(kableExtra)

options(scipen=999)</code></pre>
</div>
<div id="derive-the-search-engine-frequency-estimates" class="section level1">
<h1>Derive the search engine frequency estimates</h1>
<div id="data-loading-and-preparation" class="section level2">
<h2>Data loading and preparation</h2>
<p>The csv files contain the raw data. These cannot be shared in raw form, but transformations of the raw data are publicly available on Dataverse (see the link below and on the home page). Here, we show how the raw data are loaded, for cleaning and description. Further down in the code, we show the data being saved into the format posted on Dataverse.</p>
<pre class="r"><code>serps_person &lt;- read_csv(here(&quot;../../TDAfreqdata/SERPs/serps_rawdata_file_person.csv&quot;))
serps_woman &lt;- read_csv(here(&quot;../../TDAfreqdata/SERPs/serps_rawdata_file_woman.csv&quot;))
serps_man &lt;- read_csv(here(&quot;../../TDAfreqdata/SERPs/serps_rawdata_file_man.csv&quot;))
serps_girl &lt;- read_csv(here(&quot;../../TDAfreqdata/SERPs/serps_rawdata_file_girl.csv&quot;))
serps_boy &lt;- read_csv(here(&quot;../../TDAfreqdata/SERPs/serps_rawdata_file_boy.csv&quot;))</code></pre>
<p>Once loaded, the data are re-coded in the instances where empty results are automatically replaced with results for similarly spelled terms. See the manuscript for more description of this issue. Once cleaned, the counts from each raw data file are combined into a single data frame with all of the TDA + noun pairings.</p>
<pre class="r"><code>NOUNS_LIST &lt;- c(&quot;person&quot;, &quot;woman&quot;, &quot;man&quot;, &quot;girl&quot;, &quot;boy&quot;)

serps_person &lt;- serps_person %&gt;%
  mutate(
    count = if_else(condition = type == &quot;Empty showing fixed spelling results&quot;,
                    true = 0,
                    false = count)
  )

serps_woman &lt;- serps_woman %&gt;%
  mutate(
    count = if_else(condition = type == &quot;Empty showing fixed spelling results&quot;,
                    true = 0,
                    false = count)
  )

serps_man &lt;- serps_man %&gt;%
  mutate(
    count = if_else(condition = type == &quot;Empty showing fixed spelling results&quot;,
                    true = 0,
                    false = count)
  )

serps_girl &lt;- serps_girl %&gt;%
  mutate(
    count = if_else(condition = type == &quot;Empty showing fixed spelling results&quot;,
                    true = 0,
                    false = count)
  )

serps_boy &lt;- serps_boy %&gt;%
  mutate(
    count = if_else(condition = type == &quot;Empty showing fixed spelling results&quot;,
                    true = 0,
                    false = count)
  )

### RE-ORGANIZE SERPS DATASETS - COMBINE PERSON-WORD FORMS
serps_all &lt;- tibble(
  TDA = serps_person$term,
  person = serps_person$count,
  woman = serps_woman$count,
  man = serps_man$count,
  girl = serps_girl$count,
  boy = serps_boy$count
)

serps_all_onlyFreq &lt;- serps_all %&gt;%
  select(-TDA)</code></pre>
<p>It’s also necessary to fix special characters for many of the adjectives.</p>
<pre class="r"><code># fix characters
serps_all$TDA &lt;- sub(&quot;acharn√©&quot;, &quot;achar&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;b√™te&quot;, &quot;bête&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;blas\x8e&quot;, &quot;blasé&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;bont√©&quot;, &quot;bonté&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;bo√∂pis&quot;, &quot;boöpis&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;born√©&quot;, &quot;borné&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;d√©gag√©&quot;, &quot;dégagé&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;d√©pays√©&quot;, &quot;dépaysé&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;d√©sorient√©&quot;, &quot;désorienté&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;distingu√©&quot;, &quot;distingué&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;d√ºreresque&quot;, &quot;düreresque&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;√©clat&quot;, &quot;éclat&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;effar√©&quot;, &quot;effaré&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;√©l√©gante&quot;, &quot;élégante&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;√©lite&quot;, &quot;élite&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;ent√™t√©&quot;, &quot;entêté&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;espi√®gle&quot;, &quot;espiègle&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;fa√´rie&quot;, &quot;faërie&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;fain√©ant&quot;, &quot;fainéant&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;FALSE&quot;, &quot;false&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;outr√©&quot;, &quot;outré&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;pr√©cieuse&quot;, &quot;précieuse&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;r√©chauff√©&quot;, &quot;réchauffé&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;rou√©&quot;, &quot;roué&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;TRUE&quot;, &quot;true&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;unco√∂rdinated&quot;, &quot;uncoördinated&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;zo√∂id&quot;, &quot;zoöid&quot;, serps_all$TDA)
serps_all$TDA &lt;- sub(&quot;zo√∂philous&quot;, &quot;zoöphilous&quot;, serps_all$TDA)</code></pre>
<div id="calculate-overall-means-and-compare-differences-using-t-tests" class="section level3">
<h3>1. Calculate overall means and compare differences using t-tests</h3>
<pre class="r"><code>serps_all_means &lt;- c()
for (j in 1:ncol(serps_person))
{
  serps_all_means[j] &lt;- mean(unname(unlist(serps_all_onlyFreq[,j])), na.rm = TRUE)
}
names(serps_all_means) &lt;- NOUNS_LIST
serps_all_means</code></pre>
<pre><code>##   person    woman      man     girl      boy 
## 157458.3 129931.3 266361.2 378681.0 194969.2</code></pre>
<pre class="r"><code>serps_all_longForm &lt;- serps_all %&gt;%
  gather(form, value, person:boy)
serps_uncorrected_ttests &lt;- pairwise.t.test(x = serps_all_longForm$value, 
                                             g = serps_all_longForm$form, 
                                             p.adjust.method = &quot;none&quot;)
serps_holm_ttests &lt;- pairwise.t.test(x = serps_all_longForm$value, 
                                             g = serps_all_longForm$form, 
                                             p.adjust.method = &quot;holm&quot;)
serps_bonferroni_ttests &lt;- pairwise.t.test(x = serps_all_longForm$value, 
                                             g = serps_all_longForm$form, 
                                             p.adjust.method = &quot;bonferroni&quot;)</code></pre>
<p>Next, show the p-values for the uncorrected t-tests of means, then the holm-corrected and bonferroni-corrected p-values. None of the t-tests are significant when using corrections of either type. If using uncorrected means (not recommended), the only significant difference in means is for girl-woman; the p-value for girl-person is just above the significance threshold at p&gt;.05.</p>
<pre class="r"><code>round(serps_uncorrected_ttests$p.value, 3)</code></pre>
<pre><code>##          boy  girl   man person
## girl   0.105    NA    NA     NA
## man    0.528 0.321    NA     NA
## person 0.740 0.051 0.336     NA
## woman  0.566 0.028 0.228  0.808</code></pre>
<pre class="r"><code>round(serps_holm_ttests$p.value, 3)</code></pre>
<pre><code>##          boy  girl man person
## girl   0.837    NA  NA     NA
## man    1.000 1.000  NA     NA
## person 1.000 0.456   1     NA
## woman  1.000 0.280   1      1</code></pre>
<pre class="r"><code>round(serps_bonferroni_ttests$p.value, 3)</code></pre>
<pre><code>##        boy  girl man person
## girl     1    NA  NA     NA
## man      1 1.000  NA     NA
## person   1 0.506   1     NA
## woman    1 0.280   1      1</code></pre>
</div>
<div id="calculate-z-scores" class="section level3">
<h3>2. Calculate z-scores</h3>
<p>Now that we have compared the raw means in the prior step, we create a table of the zscores of the 10-year averages for each TDA + noun ngram. These are the data posted on Dataverse, as shown below.</p>
<pre class="r"><code>serps_all_zscores &lt;- serps_all %&gt;%
  mutate(
    TDA = serps_person$term,
    person_zscore = (person - mean(person, na.rm = TRUE))/sd(person, na.rm = TRUE),
    woman_zscore = (woman - mean(woman, na.rm = TRUE))/sd(woman, na.rm = TRUE),
    man_zscore = (man - mean(man, na.rm = TRUE))/sd(man, na.rm = TRUE),
    girl_zscore = (girl - mean(girl, na.rm = TRUE))/sd(girl, na.rm = TRUE),
    boy_zscore = (boy - mean(boy, na.rm = TRUE))/sd(boy, na.rm = TRUE)
  ) %&gt;%
  select(TDA, person_zscore:boy_zscore)</code></pre>
<pre class="r"><code>write_csv(serps_all_zscores, 
          file = here(&quot;data/serps/serps_all_zscores.csv&quot;))</code></pre>
<p>This csv file (above) has been posted publicly on Dataverse (see doi). All subsequent analyses of the search engine results data are based on this file, including the database of search engine estimates (see <a href="https://pie-lab.github.io/tdafrequency/serps-frequency.html">here</a>).</p>
<p><em>ADD DOI LINK TO THE SENTENCE ABOVE</em></p>
<p>The following code clears the environment and loads the data directly from Dataverse.</p>
<p><em>CHANGE THIS TO PULL THE ZSCORES FILE FROM DATAVERSE.</em></p>
<pre class="r"><code>rm(list=ls())
serps_all_zscores &lt;- read_csv(here(&quot;data/serps/serps_all_zscores.csv&quot;))</code></pre>
<pre class="r"><code>library(dataverse)
library(data.table)

Sys.setenv(&quot;DATAVERSE_SERVER&quot; = &quot;dataverse.harvard.edu&quot;)
writeBin(get_file(&quot;TDA_data_scored.tab&quot;, &quot;doi:10.7910/DVN/5T80PF&quot;), &quot;TDA_data_scored.tab&quot;)
TDA_data_scored.tab &lt;- fread(&quot;TDA_data_scored.tab&quot;, na.strings=getOption(&quot;&lt;NA&gt;&quot;,&quot;NA&quot;))
data &lt;- as.data.frame(TDA_data_scored.tab)
rm(TDA_data_scored.tab)</code></pre>
</div>
<div id="correlations-between-the-5-tda-noun-vectors" class="section level3">
<h3>3. Correlations between the 5 TDA + noun vectors</h3>
<pre class="r"><code>serps_zscores &lt;- subset(serps_all_zscores, select = -c(TDA))
cor_table_serps &lt;- corr.test(serps_zscores, 
                                    use = &quot;pairwise&quot;,
                                    method = &quot;pearson&quot;,
                                    alpha = .05,
                                    ci = TRUE)

cor_serps_ci &lt;- tibble(
  group1 = c(&quot;person&quot;, &quot;person&quot;, &quot;person&quot;, &quot;person&quot;, &quot;woman&quot;, 
             &quot;woman&quot;, &quot;woman&quot;, &quot;man&quot;, &quot;man&quot;, &quot;girl&quot;),
  group2 = c(&quot;woman&quot;, &quot;man&quot;, &quot;girl&quot;, &quot;boy&quot;, &quot;man&quot;, 
             &quot;girl&quot;, &quot;boy&quot;, &quot;girl&quot;, &quot;boy&quot;, &quot;boy&quot;),
  lower_bound = cor_table_serps$ci$lower,
  r = cor_table_serps$ci$r,
  upper_bound = cor_table_serps$ci$upper,
  p_value = cor_table_serps$ci$p
)</code></pre>
<p>The table below shows the correlations between noun pairs with the lower and upper bounds of the 95% confidence intervals.</p>
<pre><code>##    group1 group2 lower_bound     r upper_bound p_value
## 1  person  woman       0.058 0.072       0.086       0
## 2  person    man       0.055 0.070       0.084       0
## 3  person   girl       0.055 0.069       0.084       0
## 4  person    boy       0.049 0.063       0.078       0
## 5   woman    man       0.388 0.400       0.412       0
## 6   woman   girl       0.344 0.357       0.369       0
## 7   woman    boy       0.196 0.210       0.224       0
## 8     man   girl       0.942 0.944       0.945       0
## 9     man    boy       0.940 0.941       0.943       0
## 10   girl    boy       0.959 0.960       0.961       0</code></pre>
</div>
<div id="calculate-the-search-engine-frequency-index" class="section level3">
<h3>4. Calculate the search engine frequency index</h3>
<p>Here, we find the frequencies index by finding the average of the z-scores across all 5 TDA + noun pairs for each TDA <em>after</em> removing the max z-score for each TDA. In other words, find the average among all but the largest z-score for each TDA. This approach is used to reduce the skew introduced in a few cases where the pairing of a specific TDA + noun is part of a song, book, famous individual, etc.</p>
<p>Output from the following section of code is used to populate the serps column of the <a href="https://pie-lab.github.io/tdafrequency/serps-frequency.html">database of frequencies</a> provided on this website.</p>
<pre class="r"><code>bucket &lt;- c()
for (j in 1:nrow(serps_zscores)) 
{
  vector_i &lt;- c()
  vector_i &lt;- unname(unlist(serps_zscores[j,]))
  vector_i &lt;- vector_i[vector_i != max(vector_i, na.rm = TRUE)]
  freq_val &lt;- mean(vector_i, na.rm = TRUE)
  bucket[j] &lt;- freq_val
}

serps_freq_index &lt;- serps_zscores %&gt;%
  mutate(
    TDA = serps_all_zscores$TDA,
    freq_index = bucket
  )  %&gt;%
    select(TDA, everything())</code></pre>
</div>
</div>
</div>
<div id="derive-the-ngram-frequency-estimates" class="section level1">
<h1>Derive the ngram frequency estimates</h1>
<div id="data-loading-and-preparation-1" class="section level2">
<h2>Data loading and preparation</h2>
<p>The csv files contain the raw data. As with the search engine results, these cannot be shared in raw form, but transformations of the raw data are publicly available on Dataverse (see the link below and on the home page). Here, we show how the raw data are loaded, for cleaning and description. Further down in the code, we show the data being saved into the format available on Dataverse.</p>
<pre class="r"><code>ngrams_person &lt;- read_csv(&quot;../../TDAfreqdata/ngrams/ngrams_rawdata_file_person.csv&quot;)
ngrams_woman &lt;- read_csv(&quot;../../TDAfreqdata/ngrams/ngrams_rawdata_file_woman.csv&quot;)
ngrams_man &lt;- read_csv(&quot;../../TDAfreqdata/ngrams/ngrams_rawdata_file_man.csv&quot;)
ngrams_girl &lt;- read_csv(&quot;../../TDAfreqdata/ngrams/ngrams_rawdata_file_girl.csv&quot;)
ngrams_boy &lt;- read_csv(&quot;../../TDAfreqdata/ngrams/ngrams_rawdata_file_boy.csv&quot;)</code></pre>
<p>Once loaded, we derive the means for each term + noun ngram across the 10 year period from 2010 to 2019. These averages are then combined in a new data frame.</p>
<pre class="r"><code>NOUNS_LIST &lt;- c(&quot;person&quot;, &quot;woman&quot;, &quot;man&quot;, &quot;girl&quot;, &quot;boy&quot;)

### AVERAGE NGRAMS DATA ACROSS YEARS
select_vars &lt;- c(&quot;freq.2010&quot;,&quot;freq.2011&quot;,&quot;freq.2012&quot;,&quot;freq.2013&quot;,&quot;freq.2014&quot;,
                            &quot;freq.2015&quot;,&quot;freq.2016&quot;,&quot;freq.2017&quot;,&quot;freq.2018&quot;,&quot;freq.2019&quot;)

ngrams_person &lt;- ngrams_person %&gt;%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_woman &lt;- ngrams_woman %&gt;%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_man &lt;- ngrams_man %&gt;%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_girl &lt;- ngrams_girl %&gt;%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

ngrams_boy &lt;- ngrams_boy %&gt;%
  mutate(
    freq_avg_all_years = rowMeans(select(., select_vars)),
    zscore = (freq_avg_all_years - mean(freq_avg_all_years, na.rm = TRUE)) / 
      sd(freq_avg_all_years, na.rm = TRUE)
  )

### COMBINE INTO ONE TABLE

ngrams_all_avgfreq &lt;- tibble(
  TDA = ngrams_person$term,
  freq_avg_person = ngrams_person$freq_avg_all_years,
  freq_avg_woman = ngrams_woman$freq_avg_all_years,
  freq_avg_man = ngrams_man$freq_avg_all_years,
  freq_avg_girl = ngrams_girl$freq_avg_all_years,
  freq_avg_boy = ngrams_boy$freq_avg_all_years
)</code></pre>
<p>It’s also necessary to fix special characters for many of the adjectives.</p>
<pre class="r"><code># fix characters
ngrams_all_avgfreq$TDA &lt;- sub(&quot;acharn√©&quot;, &quot;acharné&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;b√™te&quot;, &quot;bête&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;blas\x8e&quot;, &quot;blasé&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;bont√©&quot;, &quot;bonté&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;bo√∂pis&quot;, &quot;boöpis&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;born√©&quot;, &quot;borné&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;d√©gag√©&quot;, &quot;dégagé&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;d√©pays√©&quot;, &quot;dépaysé&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;d√©sorient√©&quot;, &quot;désorienté&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;distingu√©&quot;, &quot;distingué&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;d√ºreresque&quot;, &quot;düreresque&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;√©clat&quot;, &quot;éclat&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;effar√©&quot;, &quot;effaré&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;√©l√©gante&quot;, &quot;élégante&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;√©lite&quot;, &quot;élite&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;ent√™t√©&quot;, &quot;entêté&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;espi√®gle&quot;, &quot;espiègle&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;fa√´rie&quot;, &quot;faërie&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;fain√©ant&quot;, &quot;fainéant&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;FALSE&quot;, &quot;false&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;outr√©&quot;, &quot;outré&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;pr√©cieuse&quot;, &quot;précieuse&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;r√©chauff√©&quot;, &quot;réchauffé&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;rou√©&quot;, &quot;roué&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;TRUE&quot;, &quot;true&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;unco√∂rdinated&quot;, &quot;uncoördinated&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;zo√∂id&quot;, &quot;zoöid&quot;, ngrams_all_avgfreq$TDA)
ngrams_all_avgfreq$TDA &lt;- sub(&quot;zo√∂philous&quot;, &quot;zoöphilous&quot;, ngrams_all_avgfreq$TDA)</code></pre>
</div>
<div id="analyses" class="section level2">
<h2>Analyses</h2>
<div id="calculate-overall-means-and-compare-differences-using-t-tests-1" class="section level3">
<h3>1. Calculate overall means and compare differences using t-tests</h3>
<p>Calculate the overall means for each of the TDA + noun vectors. In other words, find the means for all the TDA + person ngrams, TDA + man ngrams, woman, girl, and boy. Then compare the means with t-tests. This is repeated using holm and bonferroni corrections.</p>
<pre class="r"><code># drop the column of TDA labels
ngrams_avgfreq &lt;- subset(ngrams_all_avgfreq, select = -c(TDA))
means_vector &lt;- c()
for (j in 1:ncol(ngrams_avgfreq))
{
  means_vector[j] &lt;- mean( unname(unlist(ngrams_avgfreq[,j])), na.rm = TRUE)
}

names(means_vector) &lt;- NOUNS_LIST
means_vector</code></pre>
<pre><code>##            person             woman               man              girl 
## 0.000000009147355 0.000000009897305 0.000000018108562 0.000000008428365 
##               boy 
## 0.000000005711492</code></pre>
<pre class="r"><code>ngrams_all_longForm &lt;- ngrams_avgfreq %&gt;%
  gather(form, value, freq_avg_person:freq_avg_boy)

ngrams_uncorrected_ttests &lt;- pairwise.t.test(x = ngrams_all_longForm$value, 
                                             g = ngrams_all_longForm$form, 
                                             p.adjust.method = &quot;none&quot;)
ngrams_holm_ttests &lt;- pairwise.t.test(x = ngrams_all_longForm$value, 
                                             g = ngrams_all_longForm$form, 
                                             p.adjust.method = &quot;holm&quot;)
ngrams_bonferroni_ttests &lt;- pairwise.t.test(x = ngrams_all_longForm$value, 
                                             g = ngrams_all_longForm$form, 
                                             p.adjust.method = &quot;bonferroni&quot;)</code></pre>
<p>Next, show the p-values for the uncorrected t-tests of means, then the holm-corrected and bonferroni-corrected p-values. None of the t-tests are significant when using corrections of either type. If using uncorrected means (not recommended), the largest differences in means are for boy-man, person-man, girl-man, woman-man (in that order).</p>
<pre class="r"><code>round(ngrams_uncorrected_ttests$p.value, 3)</code></pre>
<pre><code>##                 freq_avg_boy freq_avg_girl freq_avg_man freq_avg_person
## freq_avg_girl          0.607            NA           NA              NA
## freq_avg_man           0.007         0.034           NA              NA
## freq_avg_person        0.485         0.883        0.031              NA
## freq_avg_woman         0.392         0.762        0.046           0.866</code></pre>
<pre class="r"><code>round(ngrams_holm_ttests$p.value, 3)</code></pre>
<pre><code>##                 freq_avg_boy freq_avg_girl freq_avg_man freq_avg_person
## freq_avg_girl          1.000            NA           NA              NA
## freq_avg_man           0.072         0.279           NA              NA
## freq_avg_person        1.000         1.000        0.279              NA
## freq_avg_woman         1.000         1.000        0.324               1</code></pre>
<pre class="r"><code>round(ngrams_bonferroni_ttests$p.value, 3)</code></pre>
<pre><code>##                 freq_avg_boy freq_avg_girl freq_avg_man freq_avg_person
## freq_avg_girl          1.000            NA           NA              NA
## freq_avg_man           0.072         0.344           NA              NA
## freq_avg_person        1.000         1.000        0.310              NA
## freq_avg_woman         1.000         1.000        0.462               1</code></pre>
</div>
<div id="calculate-z-scores-1" class="section level3">
<h3>2. Calculate z-scores</h3>
<p>Now that we have compared the raw means in the prior step, we create a table of the zscores of the 10-year averages for each TDA + noun ngram. These are the data posted on Dataverse, as shown below.</p>
<pre class="r"><code>ngrams_all_zscores &lt;- tibble(
  TDA = ngrams_person$term,
  coded = ngrams_person$coded,
  person_zscore = ngrams_person$zscore,
  woman_zscore = ngrams_woman$zscore,
  man_zscore = ngrams_man$zscore,
  girl_zscore = ngrams_girl$zscore,
  boy_zscore = ngrams_boy$zscore
)</code></pre>
<pre class="r"><code>write_csv(ngrams_all_zscores, 
          file = here(&quot;data/ngrams/ngrams_all_zscores.csv&quot;))</code></pre>
<p>This csv file (above) has been posted publicly on Dataverse (see doi). All subsequent analyses of the ngrams data are based on this file, including the database of ngram estimates (see <a href="https://pie-lab.github.io/tdafrequency/ngrams-frequency.html">here</a>).</p>
<p><em>ADD DOI LINK TO THE SENTENCE ABOVE</em></p>
<p>The following code clears the environment and loads the data directly from Dataverse.</p>
<p><em>CHANGE THIS TO PULL THE ZSCORES FILE FROM DATAVERSE.</em></p>
<pre class="r"><code>rm(list=ls())
ngrams_all_zscores &lt;- read_csv(here(&quot;data/ngrams/ngrams_all_zscores.csv&quot;))</code></pre>
<pre class="r"><code>library(dataverse)
library(data.table)

Sys.setenv(&quot;DATAVERSE_SERVER&quot; = &quot;dataverse.harvard.edu&quot;)
writeBin(get_file(&quot;TDA_data_scored.tab&quot;, &quot;doi:10.7910/DVN/5T80PF&quot;), &quot;TDA_data_scored.tab&quot;)
TDA_data_scored.tab &lt;- fread(&quot;TDA_data_scored.tab&quot;, na.strings=getOption(&quot;&lt;NA&gt;&quot;,&quot;NA&quot;))
data &lt;- as.data.frame(TDA_data_scored.tab)
rm(TDA_data_scored.tab)</code></pre>
</div>
<div id="correlations-between-the-5-tda-noun-vectors-1" class="section level3">
<h3>3. Correlations between the 5 TDA + noun vectors</h3>
<pre class="r"><code># drop the column of TDA labels
ngrams_zscores &lt;- subset(ngrams_all_zscores, select = -c(TDA, coded))
cor_ngrams &lt;- corr.test(ngrams_zscores,
                        use = &quot;pairwise&quot;, 
                        method = &quot;pearson&quot;, 
                        alpha = 0.05,
                        ci = TRUE)

cor_ngrams_ci &lt;- tibble(
  noun1 = c(&quot;person&quot;, &quot;person&quot;, &quot;person&quot;, &quot;person&quot;, &quot;woman&quot;, 
             &quot;woman&quot;, &quot;woman&quot;, &quot;man&quot;, &quot;man&quot;, &quot;girl&quot;),
  noun2 = c(&quot;woman&quot;, &quot;man&quot;, &quot;girl&quot;, &quot;boy&quot;, &quot;man&quot;, 
             &quot;girl&quot;, &quot;boy&quot;, &quot;girl&quot;, &quot;boy&quot;, &quot;boy&quot;),
  lower_bound = cor_ngrams$ci$lower,
  r = cor_ngrams$ci$r,
  upper_bound = cor_ngrams$ci$upper,
  p_value = cor_ngrams$ci$p
)</code></pre>
<p>The table below shows the correlations between noun pairs with the lower and upper bounds of the 95% confidence intervals.</p>
<pre><code>##     noun1 noun2 lower_bound     r upper_bound p_value
## 1  person woman       0.344 0.371       0.397       0
## 2  person   man       0.313 0.339       0.364       0
## 3  person  girl       0.164 0.198       0.232       0
## 4  person   boy       0.179 0.214       0.248       0
## 5   woman   man       0.959 0.961       0.963       0
## 6   woman  girl       0.427 0.454       0.481       0
## 7   woman   boy       0.532 0.557       0.581       0
## 8     man  girl       0.443 0.469       0.495       0
## 9     man   boy       0.589 0.610       0.631       0
## 10   girl   boy       0.952 0.956       0.959       0</code></pre>
</div>
<div id="calculate-the-ngrams-frequency-index" class="section level3">
<h3>4. Calculate the Ngrams frequency index</h3>
<p>Here, we find the frequencies index by finding the average of the z-scores across all 5 TDA + noun pairs for each TDA <em>after</em> removing the max z-score for each TDA. In other words, find the average among all but the largest z-score for each TDA. This approach is used to reduce the skew introduced in a few cases where the pairing of a specific TDA + noun is part of a song, book, famous individual, etc.</p>
<p>Output from the following section of code is used to populate the ngram column of the <a href="https://pie-lab.github.io/tdafrequency/ngrams-frequency.html">database of frequencies</a> provided on this website.</p>
<pre class="r"><code>bucket &lt;- c()
for (j in 1:nrow(ngrams_zscores)) 
{
  vector_i &lt;- c()
  vector_i &lt;- unname(unlist(ngrams_zscores[j,]))
  vector_i &lt;- vector_i[vector_i != max(vector_i, na.rm = TRUE)] #remove max zsc
  freq_val &lt;- mean(vector_i, na.rm = TRUE)
  bucket[j] &lt;- freq_val
}

ngrams_freq_index &lt;- ngrams_zscores %&gt;%
  mutate(
    freq_index = bucket
  ) 

ngrams_freq_index &lt;- ngrams_freq_index %&gt;%
  mutate(
    TDA = ngrams_all_zscores$TDA,
    freq_index = if_else(condition = is.nan(freq_index), 
                         true = as.double(NA), 
                         false = freq_index),
  ) %&gt;%
    select(TDA, everything())</code></pre>
</div>
</div>
</div>
<div id="correlation-between-search-engine-and-ngram-estimates" class="section level1">
<h1>Correlation between search engine and ngram estimates</h1>
<p>This is done by creating a large data frame with all the search engine and ngram estimates for each descriptor. Note that (1) the confidence intervals for some of the correlations involving ngram values are very wide due to large numbers of missing observations, and (2) there is a more nicely formatted table in the manuscript referenced at the top of this page.</p>
<pre class="r"><code>ngrams &lt;- as.data.frame(ngrams_freq_index)[,c(&quot;person_zscore&quot;, &quot;woman_zscore&quot;, &quot;man_zscore&quot;, &quot;girl_zscore&quot;, &quot;boy_zscore&quot;, &quot;freq_index&quot;)]
rownames(ngrams) &lt;- as.data.frame(ngrams_freq_index)[,&quot;TDA&quot;]
colnames(ngrams) &lt;- c(&quot;person_ngrams&quot;, &quot;woman_ngrams&quot;, &quot;man_ngrams&quot;, &quot;girl_ngrams&quot;, &quot;boy_ngrams&quot;, &quot;index_ngrams&quot;)

serps_freq_index &lt;- read_csv(here(&quot;data/serps/serps_freq_index.csv&quot;))
serps &lt;- as.data.frame(serps_freq_index)[,c(&quot;person_zscore&quot;, &quot;woman_zscore&quot;, &quot;man_zscore&quot;, &quot;girl_zscore&quot;, &quot;boy_zscore&quot;, &quot;freq_index&quot;)]
rownames(serps) &lt;- as.data.frame(serps_freq_index)[,&quot;TDA&quot;]
colnames(serps) &lt;- c(&quot;person_serps&quot;, &quot;woman_serps&quot;, &quot;man_serps&quot;, &quot;girl_serps&quot;, &quot;boy_serps&quot;, &quot;index_serps&quot;)

all &lt;- data.frame(serps, ngrams)
all_cor &lt;- corCi(all, plot = FALSE)
all_cor</code></pre>
<pre><code>## Call:corCi(x = all, plot = FALSE)
## 
##  Coefficients and bootstrapped confidence intervals 
##               prsn_s wmn_s mn_sr grl_s by_sr indx_s prsn_n wmn_n mn_ng grl_n by_ng indx_n
## person_serps  1.00                                                                       
## woman_serps   0.07   1.00                                                                
## man_serps     0.07   0.40  1.00                                                          
## girl_serps    0.07   0.36  0.94  1.00                                                    
## boy_serps     0.06   0.21  0.94  0.96  1.00                                              
## index_serps   0.08   0.41  0.98  0.97  0.97  1.00                                        
## person_ngrams 0.16   0.38  0.29  0.23  0.27  0.49   1.00                                 
## woman_ngrams  0.05   0.91  0.84  0.56  0.47  0.89   0.37   1.00                          
## man_ngrams    0.04   0.81  0.90  0.52  0.47  0.88   0.34   0.96  1.00                    
## girl_ngrams   0.02   0.41  0.39  0.49  0.83  0.53   0.20   0.45  0.47  1.00              
## boy_ngrams    0.02   0.45  0.56  0.52  0.81  0.64   0.21   0.56  0.61  0.96  1.00        
## index_ngrams  0.05   0.82  0.81  0.60  0.70  0.89   0.41   0.92  0.93  0.73  0.81  1.00  
## 
##  scale correlations and bootstrapped confidence intervals 
##               lower.emp lower.norm estimate upper.norm upper.emp    p
## prsn_s-wmn_s       0.04      -0.11     0.07       0.51      0.49 0.20
## prsn_s-mn_sr       0.03      -0.21     0.07       0.58      0.63 0.32
## prsn_s-grl_s       0.03      -0.21     0.07       0.57      0.61 0.34
## prsn_s-by_sr       0.02      -0.21     0.06       0.55      0.59 0.34
## prsn_s-indx_s      0.05      -0.18     0.08       0.65      0.64 0.24
## prsn_s-prsn_n      0.06      -0.38     0.16       0.96      0.94 0.28
## prsn_s-wmn_n       0.02      -0.14     0.05       0.50      0.54 0.26
## prsn_s-mn_ng       0.02      -0.15     0.04       0.46      0.50 0.30
## prsn_s-grl_n       0.01      -0.15     0.02       0.38      0.47 0.37
## prsn_s-by_ng       0.01      -0.12     0.02       0.34      0.41 0.34
## prsn_s-indx_n      0.03      -0.15     0.05       0.51      0.53 0.26
## wmn_s-mn_sr        0.33       0.04     0.40       0.85      0.86 0.07
## wmn_s-grl_s        0.33       0.07     0.36       0.80      0.84 0.04
## wmn_s-by_sr        0.19      -0.12     0.21       0.72      0.81 0.15
## wmn_s-indx_s       0.37      -0.07     0.41       0.93      0.93 0.14
## wmn_s-prsn_n       0.18       0.22     0.38       0.54      0.53 0.00
## wmn_s-wmn_n        0.77       0.71     0.91       0.98      0.98 0.01
## wmn_s-mn_ng        0.30       0.41     0.81       0.95      0.96 0.03
## wmn_s-grl_n        0.14      -0.17     0.41       0.93      0.95 0.17
## wmn_s-by_ng        0.13       0.03     0.45       0.84      0.84 0.07
## wmn_s-indx_n       0.38       0.43     0.82       0.95      0.94 0.02
## mn_sr-grl_s        0.41       0.34     0.94       0.99      0.99 0.13
## mn_sr-by_sr        0.19       0.18     0.94       0.99      0.99 0.18
## mn_sr-indx_s       0.75       0.75     0.98       1.00      1.00 0.10
## mn_sr-prsn_n       0.16       0.10     0.29       0.55      0.56 0.01
## mn_sr-wmn_n        0.44       0.55     0.84       0.96      0.96 0.01
## mn_sr-mn_ng        0.65       0.67     0.90       0.98      0.97 0.01
## mn_sr-grl_n        0.22      -0.02     0.39       0.88      0.89 0.10
## mn_sr-by_ng        0.29       0.05     0.56       0.93      0.94 0.09
## mn_sr-indx_n       0.50       0.58     0.81       0.94      0.94 0.00
## grl_s-by_sr        0.43       0.39     0.96       0.99      0.99 0.13
## grl_s-indx_s       0.66       0.63     0.97       1.00      1.00 0.11
## grl_s-prsn_n       0.10       0.05     0.23       0.44      0.48 0.02
## grl_s-wmn_n        0.38       0.29     0.56       0.81      0.83 0.00
## grl_s-mn_ng        0.27       0.22     0.52       0.79      0.79 0.01
## grl_s-grl_n        0.34       0.25     0.49       0.78      0.78 0.00
## grl_s-by_ng        0.28       0.23     0.52       0.78      0.79 0.01
## grl_s-indx_n       0.33       0.27     0.60       0.84      0.86 0.01
## by_sr-indx_s       0.37       0.43     0.97       0.99      0.99 0.14
## by_sr-prsn_n       0.13       0.09     0.27       0.49      0.51 0.01
## by_sr-wmn_n        0.08      -0.04     0.47       0.83      0.84 0.10
## by_sr-mn_ng        0.11       0.04     0.47       0.84      0.85 0.06
## by_sr-grl_n        0.24       0.36     0.83       0.94      0.92 0.02
## by_sr-by_ng        0.26       0.37     0.81       0.95      0.93 0.03
## by_sr-indx_n       0.22       0.30     0.70       0.90      0.88 0.02
## indx_s-prsn_n      0.28       0.33     0.49       0.67      0.65 0.00
## indx_s-wmn_n       0.73       0.76     0.89       0.96      0.96 0.00
## indx_s-mn_ng       0.62       0.66     0.88       0.96      0.96 0.00
## indx_s-grl_n       0.37       0.13     0.53       0.92      0.92 0.06
## indx_s-by_ng       0.39       0.25     0.64       0.91      0.93 0.03
## indx_s-indx_n      0.67       0.72     0.89       0.96      0.96 0.00
## prsn_n-wmn_n       0.20       0.20     0.37       0.58      0.61 0.00
## prsn_n-mn_ng       0.18       0.15     0.34       0.60      0.61 0.00
## prsn_n-grl_n       0.09       0.03     0.20       0.52      0.54 0.03
## prsn_n-by_ng       0.10       0.06     0.21       0.48      0.49 0.02
## prsn_n-indx_n      0.28       0.25     0.41       0.63      0.63 0.00
## wmn_n-mn_ng        0.55       0.76     0.96       0.99      0.99 0.03
## wmn_n-grl_n        0.21      -0.17     0.45       0.97      0.97 0.19
## wmn_n-by_ng        0.26       0.02     0.56       0.94      0.94 0.10
## wmn_n-indx_n       0.63       0.64     0.92       0.99      0.99 0.05
## mn_ng-grl_n        0.31      -0.06     0.47       0.96      0.96 0.15
## mn_ng-by_ng        0.39       0.09     0.61       0.96      0.97 0.11
## mn_ng-indx_n       0.79       0.79     0.93       0.99      0.99 0.02
## grl_n-by_ng        0.81       0.80     0.96       0.99      0.99 0.01
## grl_n-indx_n       0.70       0.38     0.73       0.98      0.98 0.08
## by_ng-indx_n       0.75       0.63     0.81       0.96      0.97 0.00</code></pre>
</div>
<div id="comparison-with-roivainen-2013" class="section level1">
<h1>Comparison with Roivainen (2013)</h1>
<p>As pre-registered, we evaluated the correlation between the frequency estimates presented here and the estimates reported in Roivainen (2013). This was done using z-scored versions of the raw counts provided by Roivainen (personal correspondence).</p>
<pre class="r"><code>rm(list=ls())
roivainen &lt;- read_csv(here(&quot;data/other/roivainen_comparison.csv&quot;))

serps_freq_index &lt;- read_csv(here(&quot;data/serps/serps_freq_index.csv&quot;))
serps_freq &lt;- as.data.frame(serps_freq_index[,c(&quot;person_zscore&quot;, &quot;freq_index&quot;)])
rownames(serps_freq) &lt;- serps_freq_index$TDA
roivainen_435_serps &lt;- serps_freq[as.data.frame(roivainen)[,1],]
colnames(roivainen_435_serps) &lt;- c(&quot;person_serps&quot;, &quot;index_serps&quot;)

ngrams_freq_index &lt;- read_csv(here(&quot;data/ngrams/ngrams_freq_index.csv&quot;))
ngrams_freq &lt;- as.data.frame(ngrams_freq_index[,c(&quot;person_zscore&quot;, &quot;freq_index&quot;)])
rownames(ngrams_freq) &lt;- ngrams_freq_index$TDA
roivainen_435_ngrams &lt;- ngrams_freq[as.data.frame(roivainen)[,1],]
colnames(roivainen_435_ngrams) &lt;- c(&quot;person_ngrams&quot;, &quot;index_ngrams&quot;)

roivainen &lt;- data.frame(roivainen[,&quot;Rserps2012z&quot;], roivainen_435_serps, roivainen[,&quot;Rngrams2000z&quot;], roivainen_435_ngrams)
roivainenCor &lt;- corCi(roivainen, plot = FALSE)

roiCor_df &lt;- data.frame(roivainenCor$ci[,c(&quot;low.e&quot;)], roivainenCor$means, roivainenCor$ci[,c(&quot;up.e&quot;, &quot;p&quot;)])
colnames(roiCor_df) &lt;- c(&quot;lowerCI&quot;, &quot;r&quot;, &quot;upperCI&quot;, &quot;p_value&quot;)
roiCor_df &lt;- roiCor_df[c(&quot;R2012-prsn_s&quot;, &quot;R2012-indx_s&quot;, &quot;R2000-prsn_n&quot;, &quot;R2000-indx_n&quot;),]
rownames(roiCor_df) &lt;- c(&quot;serps_person2012z-serps_person2022z&quot;, &quot;serps_person2012z-serps_freq_index2022&quot;, &quot;ngrams_person2000z-ngrams_person2019z&quot;, &quot;ngrams_person2000z-ngrams_freq_index2019&quot;)
round(roiCor_df,3)</code></pre>
<pre><code>##                                          lowerCI     r upperCI p_value
## serps_person2012z-serps_person2022z        0.792 0.864   0.906   0.000
## serps_person2012z-serps_freq_index2022     0.129 0.340   0.685   0.095
## ngrams_person2000z-ngrams_person2019z      0.623 0.897   0.969   0.007
## ngrams_person2000z-ngrams_freq_index2019   0.200 0.352   0.578   0.002</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
